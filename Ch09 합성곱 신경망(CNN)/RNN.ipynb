{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCq2UCUvEkhh"
      },
      "source": [
        "<시작하세요! 텐서플로 2.0 프로그래밍> 예제코드입니다.\n",
        "\n",
        "- 예제 코드를 실행하기 위해서는 [파일] > [드라이브에 사본 저장]으로 본인의 계정에 사본을 만든 다음 실행하면 됩니다.\n",
        "- 예제 코드는 [깃허브 저장소](https://github.com/wikibook/tf2)에서도 동일하게 제공됩니다. 예제에 대한 질문이나 책에 대한 질문은 깃허브 저장소의 [Issues](https://github.com/wikibook/tf2/issues)에 올려주세요.\n",
        "- 각 장의 예제 파일은 처음부터 끝까지 실행하는 상황을 가정하고 작성되었습니다. 혹시 세션이 다운되는 등의 이유로 실행이 되지 않는 경우가 있다면, 필요한 라이브러리를 import 하신 후에 실행하시면 됩니다. (tensorflow, numpy, pandas 등)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gl58Zr-ZKjRE",
        "outputId": "d0b8267a-8c30-4e57-9406-80b97ebecef6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 텐서플로 2 버전 선택\n",
        "try:\n",
        "    # %tensorflow_version only exists in Colab.\n",
        "    %tensorflow_version 2.x\n",
        "except Exception:\n",
        "    pass\n",
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSciZqogK0Mg"
      },
      "source": [
        "# 7.2 주요 레이어 정리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DmYqaWfcxJa"
      },
      "source": [
        "## 7.2.1 SimpleRNN 레이어"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0f2FG66cx27"
      },
      "source": [
        "# 7.1 SimpleRNN 레이어 생성 코드\n",
        "rnn1 = tf.keras.layers.SimpleRNN(units=1, activation='tanh', return_sequences=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vU4_rMdw47Au",
        "outputId": "8f6cfc9f-a7c0-40d9-a546-11ec6421afd6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 7.2 시퀀스 예측 데이터 생성\n",
        "X = []\n",
        "Y = []\n",
        "for i in range(6):\n",
        "    # [0,1,2,3], [1,2,3,4] 같은 정수의 시퀀스를 만듭니다.\n",
        "    lst = list(range(i,i+4))\n",
        "\n",
        "    # 위에서 구한 시퀀스의 숫자들을 각각 10으로 나눈 다음 저장합니다.\n",
        "    # SimpleRNN 에 각 타임스텝에 하나씩 숫자가 들어가기 때문에 여기서도 하나씩 분리해서 배열에 저장합니다.\n",
        "    X.append(list(map(lambda c: [c/10], lst)))\n",
        "\n",
        "    # 정답에 해당하는 4, 5 등의 정수를 역시 위처럼 10으로 나눠서 저장합니다.\n",
        "    Y.append((i+4)/10)\n",
        "    \n",
        "X = np.array(X)\n",
        "Y = np.array(Y)\n",
        "for i in range(len(X)):\n",
        "    print(X[i], Y[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. ]\n",
            " [0.1]\n",
            " [0.2]\n",
            " [0.3]] 0.4\n",
            "[[0.1]\n",
            " [0.2]\n",
            " [0.3]\n",
            " [0.4]] 0.5\n",
            "[[0.2]\n",
            " [0.3]\n",
            " [0.4]\n",
            " [0.5]] 0.6\n",
            "[[0.3]\n",
            " [0.4]\n",
            " [0.5]\n",
            " [0.6]] 0.7\n",
            "[[0.4]\n",
            " [0.5]\n",
            " [0.6]\n",
            " [0.7]] 0.8\n",
            "[[0.5]\n",
            " [0.6]\n",
            " [0.7]\n",
            " [0.8]] 0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFdjOc6G5kO1",
        "outputId": "4812232e-a234-4a0b-cbeb-604b2567f376",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 7.3 시퀀스 예측 모델 정의\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.SimpleRNN(units=10, return_sequences=False, input_shape=[4,1]),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn_2 (SimpleRNN)    (None, 10)                120       \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 131\n",
            "Trainable params: 131\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "LUly58bAGm3D"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7odqgVWw5oyH",
        "outputId": "37d95926-f65f-492f-e46a-070f547aba71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 7.4 네트워크 훈련 및 결과 확인\n",
        "model.fit(X, Y, epochs=100, verbose=0)\n",
        "print(np.shape(X))\n",
        "print(model.predict(X))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6, 4, 1)\n",
            "1/1 [==============================] - 0s 220ms/step\n",
            "[[0.39025816]\n",
            " [0.501847  ]\n",
            " [0.60755134]\n",
            " [0.7066053 ]\n",
            " [0.79981434]\n",
            " [0.8885553 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQUaYRRG7aWA",
        "outputId": "4f090da3-718e-4dc4-8a07-6c6f6b5851d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 7.5 학습되지 않은 시퀀스에 대한 예측 결과\n",
        "print(model.predict(np.array([[[0.6],[0.7],[0.8],[0.9]]])))\n",
        "print(model.predict(np.array([[[-0.1],[0.0],[0.1],[0.2]]])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 19ms/step\n",
            "[[0.97402054]]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "[[0.27556396]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGzdLJHZvSUg"
      },
      "source": [
        "## 7.2.2 LSTM 레이어"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYyU1BKZFDvo",
        "outputId": "deb090f2-df36-4fc3-bbe0-64565745bc51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 7.6 곱셈 문제 데이터 생성\n",
        "X = []\n",
        "Y = []\n",
        "for i in range(3000):\n",
        "    # 0~1 사이의 랜덤한 숫자 100 개를 만듭니다.\n",
        "    lst = np.random.rand(100)\n",
        "    # 마킹할 숫자 2개의 인덱스를 뽑습니다.\n",
        "    idx = np.random.choice(100, 2, replace=False)\n",
        "    # 마킹 인덱스가 저장된 원-핫 인코딩 벡터를 만듭니다.\n",
        "    zeros = np.zeros(100)\n",
        "    zeros[idx] = 1\n",
        "    # 마킹 인덱스와 랜덤한 숫자를 합쳐서 X 에 저장합니다.\n",
        "    X.append(np.array(list(zip(zeros, lst))))\n",
        "    # 마킹 인덱스가 1인 값들만 서로 곱해서 Y 에 저장합니다.\n",
        "    Y.append(np.prod(lst[idx]))\n",
        "    \n",
        "print(X[0], Y[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.         0.6382249 ]\n",
            " [0.         0.38670369]\n",
            " [0.         0.14922623]\n",
            " [0.         0.48728507]\n",
            " [0.         0.64150696]\n",
            " [0.         0.71478443]\n",
            " [0.         0.41690348]\n",
            " [0.         0.06130494]\n",
            " [0.         0.91057523]\n",
            " [0.         0.43861484]\n",
            " [0.         0.62894902]\n",
            " [0.         0.56104623]\n",
            " [0.         0.10572163]\n",
            " [0.         0.79952979]\n",
            " [0.         0.63035628]\n",
            " [0.         0.63680085]\n",
            " [0.         0.67185404]\n",
            " [0.         0.61215166]\n",
            " [0.         0.76806654]\n",
            " [0.         0.25125994]\n",
            " [0.         0.72738705]\n",
            " [0.         0.44868122]\n",
            " [0.         0.35293988]\n",
            " [0.         0.25721796]\n",
            " [0.         0.66747389]\n",
            " [0.         0.63933116]\n",
            " [1.         0.55637236]\n",
            " [0.         0.11837606]\n",
            " [0.         0.1040563 ]\n",
            " [0.         0.95372269]\n",
            " [0.         0.79121037]\n",
            " [0.         0.93289264]\n",
            " [0.         0.98653772]\n",
            " [0.         0.13065409]\n",
            " [0.         0.40871101]\n",
            " [0.         0.48924205]\n",
            " [0.         0.94570321]\n",
            " [0.         0.39999099]\n",
            " [0.         0.61891371]\n",
            " [0.         0.02725584]\n",
            " [0.         0.86958569]\n",
            " [0.         0.61551496]\n",
            " [0.         0.04243621]\n",
            " [0.         0.35283399]\n",
            " [0.         0.70126929]\n",
            " [0.         0.65876941]\n",
            " [0.         0.95893078]\n",
            " [0.         0.65822984]\n",
            " [0.         0.0362303 ]\n",
            " [0.         0.30753721]\n",
            " [0.         0.60836991]\n",
            " [0.         0.46427797]\n",
            " [0.         0.85763975]\n",
            " [0.         0.79535164]\n",
            " [0.         0.43432651]\n",
            " [0.         0.65430855]\n",
            " [0.         0.49202014]\n",
            " [0.         0.92532939]\n",
            " [0.         0.61593399]\n",
            " [0.         0.04585308]\n",
            " [0.         0.86688216]\n",
            " [0.         0.40385234]\n",
            " [0.         0.64708307]\n",
            " [0.         0.76791645]\n",
            " [0.         0.72555939]\n",
            " [0.         0.2709174 ]\n",
            " [0.         0.16873517]\n",
            " [0.         0.43941435]\n",
            " [0.         0.2281591 ]\n",
            " [0.         0.99824757]\n",
            " [0.         0.11441316]\n",
            " [0.         0.07306065]\n",
            " [0.         0.97953766]\n",
            " [0.         0.22403623]\n",
            " [0.         0.8933452 ]\n",
            " [0.         0.18305901]\n",
            " [0.         0.9195035 ]\n",
            " [0.         0.12977702]\n",
            " [0.         0.52253896]\n",
            " [0.         0.56743936]\n",
            " [0.         0.3184327 ]\n",
            " [1.         0.42594091]\n",
            " [0.         0.93899267]\n",
            " [0.         0.34901669]\n",
            " [0.         0.09115243]\n",
            " [0.         0.05593183]\n",
            " [0.         0.6961513 ]\n",
            " [0.         0.11635769]\n",
            " [0.         0.49732973]\n",
            " [0.         0.22543569]\n",
            " [0.         0.0540265 ]\n",
            " [0.         0.47345366]\n",
            " [0.         0.59195426]\n",
            " [0.         0.0068752 ]\n",
            " [0.         0.52257925]\n",
            " [0.         0.76812256]\n",
            " [0.         0.01062939]\n",
            " [0.         0.30292442]\n",
            " [0.         0.51593423]\n",
            " [0.         0.73871287]] 0.236981752571069\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doitxA8uOm5i",
        "outputId": "15d966b2-2b06-4202-c7c5-b6547a0936e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 7.7 SimpleRNN 레이어를 사용한 곱셈 문제 모델 정의\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.SimpleRNN(units=30, return_sequences=True, input_shape=[100,2]),\n",
        "    tf.keras.layers.SimpleRNN(units=30),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn_3 (SimpleRNN)    (None, 100, 30)           990       \n",
            "                                                                 \n",
            " simple_rnn_4 (SimpleRNN)    (None, 30)                1830      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 31        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,851\n",
            "Trainable params: 2,851\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTp4nvHYOqOZ",
        "outputId": "7d1f22fc-d124-4c45-87df-71054a8818da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 7.8 SimpleRNN 네트워크 학습\n",
        "X = np.array(X)\n",
        "Y = np.array(Y)\n",
        "# 2560개의 데이터만 학습시킵니다. validation 데이터는 20% 로 지정합니다.\n",
        "history = model.fit(X[:2560], Y[:2560], epochs=100, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "64/64 [==============================] - 4s 42ms/step - loss: 0.0588 - val_loss: 0.0532\n",
            "Epoch 2/100\n",
            "64/64 [==============================] - 2s 36ms/step - loss: 0.0509 - val_loss: 0.0509\n",
            "Epoch 3/100\n",
            "64/64 [==============================] - 2s 36ms/step - loss: 0.0504 - val_loss: 0.0508\n",
            "Epoch 4/100\n",
            "64/64 [==============================] - 2s 36ms/step - loss: 0.0506 - val_loss: 0.0517\n",
            "Epoch 5/100\n",
            "64/64 [==============================] - 2s 36ms/step - loss: 0.0506 - val_loss: 0.0527\n",
            "Epoch 6/100\n",
            "64/64 [==============================] - 2s 36ms/step - loss: 0.0501 - val_loss: 0.0509\n",
            "Epoch 7/100\n",
            "64/64 [==============================] - 2s 36ms/step - loss: 0.0499 - val_loss: 0.0509\n",
            "Epoch 8/100\n",
            "64/64 [==============================] - 2s 35ms/step - loss: 0.0501 - val_loss: 0.0508\n",
            "Epoch 9/100\n",
            "64/64 [==============================] - 2s 36ms/step - loss: 0.0505 - val_loss: 0.0547\n",
            "Epoch 10/100\n",
            "64/64 [==============================] - 2s 35ms/step - loss: 0.0502 - val_loss: 0.0507\n",
            "Epoch 11/100\n",
            "64/64 [==============================] - 2s 36ms/step - loss: 0.0496 - val_loss: 0.0508\n",
            "Epoch 12/100\n",
            "64/64 [==============================] - 2s 36ms/step - loss: 0.0507 - val_loss: 0.0510\n",
            "Epoch 13/100\n",
            "64/64 [==============================] - 2s 36ms/step - loss: 0.0511 - val_loss: 0.0509\n",
            "Epoch 14/100\n",
            "64/64 [==============================] - 2s 36ms/step - loss: 0.0499 - val_loss: 0.0520\n",
            "Epoch 15/100\n",
            "64/64 [==============================] - 2s 35ms/step - loss: 0.0505 - val_loss: 0.0534\n",
            "Epoch 16/100\n",
            "64/64 [==============================] - 2s 36ms/step - loss: 0.0524 - val_loss: 0.0510\n",
            "Epoch 17/100\n",
            "64/64 [==============================] - 2s 37ms/step - loss: 0.0516 - val_loss: 0.0512\n",
            "Epoch 18/100\n",
            "64/64 [==============================] - 2s 37ms/step - loss: 0.0497 - val_loss: 0.0516\n",
            "Epoch 19/100\n",
            "64/64 [==============================] - 2s 35ms/step - loss: 0.0508 - val_loss: 0.0509\n",
            "Epoch 20/100\n",
            "64/64 [==============================] - 2s 36ms/step - loss: 0.0500 - val_loss: 0.0520\n",
            "Epoch 21/100\n",
            "64/64 [==============================] - 2s 36ms/step - loss: 0.0503 - val_loss: 0.0508\n",
            "Epoch 22/100\n",
            "64/64 [==============================] - 2s 36ms/step - loss: 0.0500 - val_loss: 0.0508\n",
            "Epoch 23/100\n",
            "64/64 [==============================] - 2s 37ms/step - loss: 0.0496 - val_loss: 0.0533\n",
            "Epoch 24/100\n",
            "64/64 [==============================] - 2s 38ms/step - loss: 0.0507 - val_loss: 0.0542\n",
            "Epoch 25/100\n",
            "64/64 [==============================] - 2s 35ms/step - loss: 0.0506 - val_loss: 0.0526\n",
            "Epoch 26/100\n",
            "64/64 [==============================] - 2s 35ms/step - loss: 0.0496 - val_loss: 0.0508\n",
            "Epoch 27/100\n",
            "64/64 [==============================] - 2s 37ms/step - loss: 0.0495 - val_loss: 0.0508\n",
            "Epoch 28/100\n",
            "64/64 [==============================] - 2s 36ms/step - loss: 0.0500 - val_loss: 0.0505\n",
            "Epoch 29/100\n",
            "64/64 [==============================] - 2s 35ms/step - loss: 0.0497 - val_loss: 0.0508\n",
            "Epoch 30/100\n",
            "64/64 [==============================] - 2s 36ms/step - loss: 0.0497 - val_loss: 0.0522\n",
            "Epoch 31/100\n",
            "64/64 [==============================] - 2s 36ms/step - loss: 0.0498 - val_loss: 0.0511\n",
            "Epoch 32/100\n",
            "64/64 [==============================] - 2s 36ms/step - loss: 0.0517 - val_loss: 0.0511\n",
            "Epoch 33/100\n",
            "64/64 [==============================] - 2s 36ms/step - loss: 0.0495 - val_loss: 0.0507\n",
            "Epoch 34/100\n",
            "64/64 [==============================] - 2s 36ms/step - loss: 0.0495 - val_loss: 0.0509\n",
            "Epoch 35/100\n",
            "64/64 [==============================] - 2s 36ms/step - loss: 0.0501 - val_loss: 0.0534\n",
            "Epoch 36/100\n",
            "64/64 [==============================] - 2s 36ms/step - loss: 0.0502 - val_loss: 0.0529\n",
            "Epoch 37/100\n",
            "64/64 [==============================] - 2s 37ms/step - loss: 0.0494 - val_loss: 0.0531\n",
            "Epoch 38/100\n",
            "64/64 [==============================] - 2s 36ms/step - loss: 0.0504 - val_loss: 0.0519\n",
            "Epoch 39/100\n",
            "64/64 [==============================] - 2s 36ms/step - loss: 0.0496 - val_loss: 0.0538\n",
            "Epoch 40/100\n",
            "64/64 [==============================] - 2s 36ms/step - loss: 0.0497 - val_loss: 0.0510\n",
            "Epoch 41/100\n",
            "64/64 [==============================] - 2s 36ms/step - loss: 0.0486 - val_loss: 0.0505\n",
            "Epoch 42/100\n",
            "64/64 [==============================] - 2s 36ms/step - loss: 0.0492 - val_loss: 0.0509\n",
            "Epoch 43/100\n",
            "64/64 [==============================] - 2s 35ms/step - loss: 0.0489 - val_loss: 0.0501\n",
            "Epoch 44/100\n",
            "64/64 [==============================] - 2s 36ms/step - loss: 0.0489 - val_loss: 0.0526\n",
            "Epoch 45/100\n",
            "64/64 [==============================] - 2s 36ms/step - loss: 0.0489 - val_loss: 0.0510\n",
            "Epoch 46/100\n",
            "64/64 [==============================] - 2s 36ms/step - loss: 0.0491 - val_loss: 0.0506\n",
            "Epoch 47/100\n",
            "64/64 [==============================] - 2s 36ms/step - loss: 0.0491 - val_loss: 0.0509\n",
            "Epoch 48/100\n",
            "64/64 [==============================] - 2s 36ms/step - loss: 0.0497 - val_loss: 0.0504\n",
            "Epoch 49/100\n",
            "64/64 [==============================] - 2s 36ms/step - loss: 0.0489 - val_loss: 0.0509\n",
            "Epoch 50/100\n",
            "64/64 [==============================] - 2s 36ms/step - loss: 0.0492 - val_loss: 0.0516\n",
            "Epoch 51/100\n",
            "64/64 [==============================] - 2s 37ms/step - loss: 0.0483 - val_loss: 0.0509\n",
            "Epoch 52/100\n",
            "64/64 [==============================] - 2s 36ms/step - loss: 0.0494 - val_loss: 0.0501\n",
            "Epoch 53/100\n",
            "64/64 [==============================] - 2s 35ms/step - loss: 0.0488 - val_loss: 0.0504\n",
            "Epoch 54/100\n",
            "64/64 [==============================] - 2s 36ms/step - loss: 0.0484 - val_loss: 0.0520\n",
            "Epoch 55/100\n",
            "64/64 [==============================] - 2s 35ms/step - loss: 0.0479 - val_loss: 0.0534\n",
            "Epoch 56/100\n",
            "64/64 [==============================] - 2s 36ms/step - loss: 0.0477 - val_loss: 0.0508\n",
            "Epoch 57/100\n",
            "64/64 [==============================] - 2s 36ms/step - loss: 0.0477 - val_loss: 0.0511\n",
            "Epoch 58/100\n",
            "64/64 [==============================] - 2s 36ms/step - loss: 0.0477 - val_loss: 0.0512\n",
            "Epoch 59/100\n",
            "64/64 [==============================] - 2s 36ms/step - loss: 0.0476 - val_loss: 0.0509\n",
            "Epoch 60/100\n",
            "64/64 [==============================] - 2s 36ms/step - loss: 0.0472 - val_loss: 0.0514\n",
            "Epoch 61/100\n",
            "64/64 [==============================] - 2s 36ms/step - loss: 0.0474 - val_loss: 0.0516\n",
            "Epoch 62/100\n",
            "64/64 [==============================] - 2s 35ms/step - loss: 0.0470 - val_loss: 0.0510\n",
            "Epoch 63/100\n",
            "64/64 [==============================] - 2s 36ms/step - loss: 0.0472 - val_loss: 0.0520\n",
            "Epoch 64/100\n",
            "64/64 [==============================] - 2s 36ms/step - loss: 0.0473 - val_loss: 0.0531\n",
            "Epoch 65/100\n",
            "64/64 [==============================] - 2s 36ms/step - loss: 0.0483 - val_loss: 0.0509\n",
            "Epoch 66/100\n",
            "64/64 [==============================] - 2s 36ms/step - loss: 0.0468 - val_loss: 0.0504\n",
            "Epoch 67/100\n",
            "64/64 [==============================] - 2s 36ms/step - loss: 0.0462 - val_loss: 0.0523\n",
            "Epoch 68/100\n",
            "64/64 [==============================] - 2s 37ms/step - loss: 0.0474 - val_loss: 0.0521\n",
            "Epoch 69/100\n",
            "64/64 [==============================] - 2s 36ms/step - loss: 0.0465 - val_loss: 0.0522\n",
            "Epoch 70/100\n",
            "64/64 [==============================] - 3s 48ms/step - loss: 0.0457 - val_loss: 0.0517\n",
            "Epoch 71/100\n",
            "64/64 [==============================] - 5s 85ms/step - loss: 0.0452 - val_loss: 0.0572\n",
            "Epoch 72/100\n",
            "64/64 [==============================] - 5s 79ms/step - loss: 0.0454 - val_loss: 0.0525\n",
            "Epoch 73/100\n",
            "64/64 [==============================] - 3s 40ms/step - loss: 0.0449 - val_loss: 0.0519\n",
            "Epoch 74/100\n",
            "64/64 [==============================] - 2s 36ms/step - loss: 0.0446 - val_loss: 0.0535\n",
            "Epoch 75/100\n",
            "64/64 [==============================] - 2s 35ms/step - loss: 0.0448 - val_loss: 0.0529\n",
            "Epoch 76/100\n",
            "64/64 [==============================] - 2s 35ms/step - loss: 0.0442 - val_loss: 0.0513\n",
            "Epoch 77/100\n",
            "64/64 [==============================] - 2s 35ms/step - loss: 0.0441 - val_loss: 0.0541\n",
            "Epoch 78/100\n",
            "64/64 [==============================] - 2s 36ms/step - loss: 0.0485 - val_loss: 0.0499\n",
            "Epoch 79/100\n",
            "64/64 [==============================] - 2s 36ms/step - loss: 0.0483 - val_loss: 0.0501\n",
            "Epoch 80/100\n",
            "64/64 [==============================] - 2s 36ms/step - loss: 0.0461 - val_loss: 0.0504\n",
            "Epoch 81/100\n",
            "64/64 [==============================] - 2s 36ms/step - loss: 0.0463 - val_loss: 0.0502\n",
            "Epoch 82/100\n",
            "64/64 [==============================] - 2s 36ms/step - loss: 0.0461 - val_loss: 0.0523\n",
            "Epoch 83/100\n",
            "64/64 [==============================] - 2s 36ms/step - loss: 0.0454 - val_loss: 0.0501\n",
            "Epoch 84/100\n",
            "64/64 [==============================] - 2s 37ms/step - loss: 0.0448 - val_loss: 0.0519\n",
            "Epoch 85/100\n",
            "64/64 [==============================] - 2s 36ms/step - loss: 0.0444 - val_loss: 0.0506\n",
            "Epoch 86/100\n",
            "64/64 [==============================] - 2s 36ms/step - loss: 0.0456 - val_loss: 0.0515\n",
            "Epoch 87/100\n",
            "64/64 [==============================] - 2s 36ms/step - loss: 0.0438 - val_loss: 0.0519\n",
            "Epoch 88/100\n",
            "64/64 [==============================] - 2s 37ms/step - loss: 0.0439 - val_loss: 0.0515\n",
            "Epoch 89/100\n",
            "64/64 [==============================] - 2s 36ms/step - loss: 0.0432 - val_loss: 0.0537\n",
            "Epoch 90/100\n",
            "64/64 [==============================] - 2s 36ms/step - loss: 0.0434 - val_loss: 0.0520\n",
            "Epoch 91/100\n",
            "64/64 [==============================] - 2s 36ms/step - loss: 0.0429 - val_loss: 0.0547\n",
            "Epoch 92/100\n",
            "64/64 [==============================] - 2s 36ms/step - loss: 0.0425 - val_loss: 0.0546\n",
            "Epoch 93/100\n",
            "64/64 [==============================] - 2s 36ms/step - loss: 0.0429 - val_loss: 0.0508\n",
            "Epoch 94/100\n",
            "64/64 [==============================] - 2s 37ms/step - loss: 0.0417 - val_loss: 0.0561\n",
            "Epoch 95/100\n",
            "64/64 [==============================] - 2s 35ms/step - loss: 0.0424 - val_loss: 0.0526\n",
            "Epoch 96/100\n",
            "64/64 [==============================] - 2s 36ms/step - loss: 0.0414 - val_loss: 0.0543\n",
            "Epoch 97/100\n",
            "64/64 [==============================] - 2s 36ms/step - loss: 0.0412 - val_loss: 0.0533\n",
            "Epoch 98/100\n",
            "64/64 [==============================] - 2s 36ms/step - loss: 0.0403 - val_loss: 0.0627\n",
            "Epoch 99/100\n",
            "64/64 [==============================] - 2s 37ms/step - loss: 0.0415 - val_loss: 0.0536\n",
            "Epoch 100/100\n",
            "64/64 [==============================] - 2s 36ms/step - loss: 0.0405 - val_loss: 0.0526\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EiSvd5rOsIV",
        "outputId": "b1fa2c3c-9e33-446b-c8f0-980e8b5955d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "# 7.9 SimpleRNN 네트워크 학습 결과 확인\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['loss'], 'b-', label='loss')\n",
        "plt.plot(history.history['val_loss'], 'r--', label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5OnirteOyut",
        "outputId": "f010749a-8b96-46f4-a060-f0cc3c873ffb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 7.10 Test 데이터에 대한 예측 정확도 확인\n",
        "model.evaluate(X[2560:], Y[2560:])\n",
        "prediction = model.predict(X[2560:2560+5])\n",
        "# 5개 테스트 데이터에 대한 예측을 표시합니다.\n",
        "for i in range(5):\n",
        "    print(Y[2560+i], '\\t', prediction[i][0], '\\tdiff:', abs(prediction[i][0] - Y[2560+i]))\n",
        "    \n",
        "prediction = model.predict(X[2560:])\n",
        "fail = 0\n",
        "for i in range(len(prediction)):\n",
        "    # 오차가 0.04 이상이면 오답입니다.\n",
        "    if abs(prediction[i][0] - Y[2560+i]) > 0.04:\n",
        "        fail += 1\n",
        "print('correctness:', (440 - fail) / 440 * 100, '%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14/14 [==============================] - 0s 12ms/step - loss: 0.0497\n",
            "1/1 [==============================] - 0s 259ms/step\n",
            "0.1162097578656399 \t 0.27171695 \tdiff: 0.15550719445827366\n",
            "0.19848398653168728 \t 0.30508453 \tdiff: 0.1066005400071616\n",
            "0.05628569993520576 \t 0.21438465 \tdiff: 0.15809894528841179\n",
            "0.03480691558825324 \t 0.28667453 \tdiff: 0.2518676137257879\n",
            "0.022800598289235353 \t 0.31104067 \tdiff: 0.28824007139040636\n",
            "14/14 [==============================] - 0s 12ms/step\n",
            "correctness: 9.772727272727273 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6o1z24gWIe4B",
        "outputId": "5087b3e7-5444-475e-fc39-be8b19ff6f2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 7.11 LSTM 레이어를 사용한 곱셈 문제 모델 정의\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.LSTM(units=30, return_sequences=True, input_shape=[100,2]),\n",
        "    tf.keras.layers.LSTM(units=30),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 100, 30)           3960      \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 30)                7320      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 31        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11,311\n",
            "Trainable params: 11,311\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XavhYhX4Imax",
        "outputId": "0e8062d7-e4a8-430d-850f-ca2a7a5001a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 7.12 LSTM 네트워크 학습\n",
        "X = np.array(X)\n",
        "Y = np.array(Y)\n",
        "history = model.fit(X[:2560], Y[:2560], epochs=100, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "64/64 [==============================] - 8s 79ms/step - loss: 0.0557 - val_loss: 0.0500\n",
            "Epoch 2/100\n",
            "64/64 [==============================] - 4s 63ms/step - loss: 0.0494 - val_loss: 0.0499\n",
            "Epoch 3/100\n",
            "64/64 [==============================] - 4s 65ms/step - loss: 0.0494 - val_loss: 0.0506\n",
            "Epoch 4/100\n",
            "64/64 [==============================] - 4s 64ms/step - loss: 0.0495 - val_loss: 0.0505\n",
            "Epoch 5/100\n",
            "64/64 [==============================] - 4s 63ms/step - loss: 0.0490 - val_loss: 0.0502\n",
            "Epoch 6/100\n",
            "64/64 [==============================] - 4s 63ms/step - loss: 0.0493 - val_loss: 0.0503\n",
            "Epoch 7/100\n",
            "64/64 [==============================] - 4s 63ms/step - loss: 0.0492 - val_loss: 0.0500\n",
            "Epoch 8/100\n",
            "64/64 [==============================] - 4s 64ms/step - loss: 0.0491 - val_loss: 0.0500\n",
            "Epoch 9/100\n",
            "64/64 [==============================] - 4s 63ms/step - loss: 0.0491 - val_loss: 0.0501\n",
            "Epoch 10/100\n",
            "64/64 [==============================] - 4s 63ms/step - loss: 0.0491 - val_loss: 0.0502\n",
            "Epoch 11/100\n",
            "64/64 [==============================] - 4s 64ms/step - loss: 0.0498 - val_loss: 0.0506\n",
            "Epoch 12/100\n",
            "64/64 [==============================] - 4s 64ms/step - loss: 0.0493 - val_loss: 0.0501\n",
            "Epoch 13/100\n",
            "64/64 [==============================] - 4s 65ms/step - loss: 0.0493 - val_loss: 0.0499\n",
            "Epoch 14/100\n",
            "64/64 [==============================] - 4s 64ms/step - loss: 0.0495 - val_loss: 0.0505\n",
            "Epoch 15/100\n",
            "64/64 [==============================] - 4s 64ms/step - loss: 0.0493 - val_loss: 0.0499\n",
            "Epoch 16/100\n",
            "64/64 [==============================] - 4s 64ms/step - loss: 0.0490 - val_loss: 0.0500\n",
            "Epoch 17/100\n",
            "64/64 [==============================] - 4s 63ms/step - loss: 0.0490 - val_loss: 0.0513\n",
            "Epoch 18/100\n",
            "64/64 [==============================] - 4s 63ms/step - loss: 0.0495 - val_loss: 0.0502\n",
            "Epoch 19/100\n",
            "64/64 [==============================] - 4s 64ms/step - loss: 0.0492 - val_loss: 0.0502\n",
            "Epoch 20/100\n",
            "64/64 [==============================] - 4s 62ms/step - loss: 0.0493 - val_loss: 0.0508\n",
            "Epoch 21/100\n",
            "64/64 [==============================] - 4s 63ms/step - loss: 0.0491 - val_loss: 0.0503\n",
            "Epoch 22/100\n",
            "64/64 [==============================] - 4s 64ms/step - loss: 0.0491 - val_loss: 0.0500\n",
            "Epoch 23/100\n",
            "64/64 [==============================] - 4s 65ms/step - loss: 0.0492 - val_loss: 0.0506\n",
            "Epoch 24/100\n",
            "64/64 [==============================] - 4s 63ms/step - loss: 0.0490 - val_loss: 0.0500\n",
            "Epoch 25/100\n",
            "64/64 [==============================] - 4s 63ms/step - loss: 0.0489 - val_loss: 0.0500\n",
            "Epoch 26/100\n",
            "64/64 [==============================] - 4s 63ms/step - loss: 0.0490 - val_loss: 0.0499\n",
            "Epoch 27/100\n",
            "64/64 [==============================] - 4s 63ms/step - loss: 0.0489 - val_loss: 0.0498\n",
            "Epoch 28/100\n",
            "64/64 [==============================] - 4s 63ms/step - loss: 0.0489 - val_loss: 0.0500\n",
            "Epoch 29/100\n",
            "64/64 [==============================] - 4s 65ms/step - loss: 0.0488 - val_loss: 0.0505\n",
            "Epoch 30/100\n",
            "64/64 [==============================] - 4s 64ms/step - loss: 0.0490 - val_loss: 0.0500\n",
            "Epoch 31/100\n",
            "64/64 [==============================] - 4s 64ms/step - loss: 0.0487 - val_loss: 0.0499\n",
            "Epoch 32/100\n",
            "64/64 [==============================] - 4s 63ms/step - loss: 0.0488 - val_loss: 0.0497\n",
            "Epoch 33/100\n",
            "64/64 [==============================] - 4s 65ms/step - loss: 0.0480 - val_loss: 0.0488\n",
            "Epoch 34/100\n",
            "64/64 [==============================] - 4s 64ms/step - loss: 0.0477 - val_loss: 0.0478\n",
            "Epoch 35/100\n",
            "64/64 [==============================] - 4s 64ms/step - loss: 0.0494 - val_loss: 0.0531\n",
            "Epoch 36/100\n",
            "64/64 [==============================] - 4s 64ms/step - loss: 0.0492 - val_loss: 0.0491\n",
            "Epoch 37/100\n",
            "64/64 [==============================] - 4s 63ms/step - loss: 0.0484 - val_loss: 0.0501\n",
            "Epoch 38/100\n",
            "64/64 [==============================] - 4s 64ms/step - loss: 0.0483 - val_loss: 0.0482\n",
            "Epoch 39/100\n",
            "64/64 [==============================] - 4s 63ms/step - loss: 0.0476 - val_loss: 0.0475\n",
            "Epoch 40/100\n",
            "64/64 [==============================] - 4s 63ms/step - loss: 0.0484 - val_loss: 0.0563\n",
            "Epoch 41/100\n",
            "64/64 [==============================] - 4s 63ms/step - loss: 0.0485 - val_loss: 0.0476\n",
            "Epoch 42/100\n",
            "64/64 [==============================] - 4s 64ms/step - loss: 0.0466 - val_loss: 0.0470\n",
            "Epoch 43/100\n",
            "64/64 [==============================] - 4s 65ms/step - loss: 0.0453 - val_loss: 0.0458\n",
            "Epoch 44/100\n",
            "64/64 [==============================] - 4s 64ms/step - loss: 0.0409 - val_loss: 0.0261\n",
            "Epoch 45/100\n",
            "64/64 [==============================] - 4s 66ms/step - loss: 0.0267 - val_loss: 0.0202\n",
            "Epoch 46/100\n",
            "64/64 [==============================] - 4s 64ms/step - loss: 0.0186 - val_loss: 0.0100\n",
            "Epoch 47/100\n",
            "64/64 [==============================] - 4s 65ms/step - loss: 0.0099 - val_loss: 0.0093\n",
            "Epoch 48/100\n",
            "64/64 [==============================] - 4s 66ms/step - loss: 0.0081 - val_loss: 0.0058\n",
            "Epoch 49/100\n",
            "64/64 [==============================] - 4s 63ms/step - loss: 0.0063 - val_loss: 0.0047\n",
            "Epoch 50/100\n",
            "64/64 [==============================] - 4s 63ms/step - loss: 0.0050 - val_loss: 0.0039\n",
            "Epoch 51/100\n",
            "64/64 [==============================] - 4s 64ms/step - loss: 0.0039 - val_loss: 0.0054\n",
            "Epoch 52/100\n",
            "64/64 [==============================] - 4s 63ms/step - loss: 0.0041 - val_loss: 0.0029\n",
            "Epoch 53/100\n",
            "64/64 [==============================] - 4s 66ms/step - loss: 0.0028 - val_loss: 0.0036\n",
            "Epoch 54/100\n",
            "64/64 [==============================] - 4s 68ms/step - loss: 0.0030 - val_loss: 0.0022\n",
            "Epoch 55/100\n",
            "64/64 [==============================] - 4s 66ms/step - loss: 0.0026 - val_loss: 0.0021\n",
            "Epoch 56/100\n",
            "64/64 [==============================] - 4s 63ms/step - loss: 0.0028 - val_loss: 0.0028\n",
            "Epoch 57/100\n",
            "64/64 [==============================] - 4s 64ms/step - loss: 0.0024 - val_loss: 0.0019\n",
            "Epoch 58/100\n",
            "64/64 [==============================] - 4s 63ms/step - loss: 0.0021 - val_loss: 0.0017\n",
            "Epoch 59/100\n",
            "64/64 [==============================] - 4s 64ms/step - loss: 0.0022 - val_loss: 0.0061\n",
            "Epoch 60/100\n",
            "64/64 [==============================] - 4s 64ms/step - loss: 0.0022 - val_loss: 0.0018\n",
            "Epoch 61/100\n",
            "64/64 [==============================] - 4s 64ms/step - loss: 0.0019 - val_loss: 0.0025\n",
            "Epoch 62/100\n",
            "64/64 [==============================] - 4s 64ms/step - loss: 0.0017 - val_loss: 0.0023\n",
            "Epoch 63/100\n",
            "64/64 [==============================] - 4s 63ms/step - loss: 0.0016 - val_loss: 0.0013\n",
            "Epoch 64/100\n",
            "64/64 [==============================] - 4s 63ms/step - loss: 0.0013 - val_loss: 0.0013\n",
            "Epoch 65/100\n",
            "64/64 [==============================] - 4s 64ms/step - loss: 0.0017 - val_loss: 0.0011\n",
            "Epoch 66/100\n",
            "64/64 [==============================] - 4s 65ms/step - loss: 0.0018 - val_loss: 0.0016\n",
            "Epoch 67/100\n",
            "64/64 [==============================] - 4s 64ms/step - loss: 0.0013 - val_loss: 0.0011\n",
            "Epoch 68/100\n",
            "64/64 [==============================] - 4s 64ms/step - loss: 0.0014 - val_loss: 0.0012\n",
            "Epoch 69/100\n",
            "64/64 [==============================] - 4s 63ms/step - loss: 0.0014 - val_loss: 0.0027\n",
            "Epoch 70/100\n",
            "64/64 [==============================] - 4s 63ms/step - loss: 0.0012 - val_loss: 9.9862e-04\n",
            "Epoch 71/100\n",
            "64/64 [==============================] - 4s 65ms/step - loss: 0.0010 - val_loss: 0.0010\n",
            "Epoch 72/100\n",
            "64/64 [==============================] - 4s 64ms/step - loss: 0.0012 - val_loss: 0.0010\n",
            "Epoch 73/100\n",
            "64/64 [==============================] - 4s 63ms/step - loss: 9.3452e-04 - val_loss: 8.8890e-04\n",
            "Epoch 74/100\n",
            "64/64 [==============================] - 4s 64ms/step - loss: 8.6025e-04 - val_loss: 7.7880e-04\n",
            "Epoch 75/100\n",
            "64/64 [==============================] - 4s 63ms/step - loss: 0.0011 - val_loss: 0.0018\n",
            "Epoch 76/100\n",
            "64/64 [==============================] - 4s 63ms/step - loss: 7.7568e-04 - val_loss: 9.1794e-04\n",
            "Epoch 77/100\n",
            "64/64 [==============================] - 4s 63ms/step - loss: 8.8878e-04 - val_loss: 0.0015\n",
            "Epoch 78/100\n",
            "64/64 [==============================] - 4s 63ms/step - loss: 0.0013 - val_loss: 9.1516e-04\n",
            "Epoch 79/100\n",
            "64/64 [==============================] - 4s 63ms/step - loss: 8.9735e-04 - val_loss: 0.0013\n",
            "Epoch 80/100\n",
            "64/64 [==============================] - 4s 63ms/step - loss: 8.3663e-04 - val_loss: 7.4235e-04\n",
            "Epoch 81/100\n",
            "64/64 [==============================] - 4s 63ms/step - loss: 6.7787e-04 - val_loss: 9.2080e-04\n",
            "Epoch 82/100\n",
            "64/64 [==============================] - 4s 64ms/step - loss: 6.4494e-04 - val_loss: 0.0011\n",
            "Epoch 83/100\n",
            "64/64 [==============================] - 4s 63ms/step - loss: 6.3844e-04 - val_loss: 7.8159e-04\n",
            "Epoch 84/100\n",
            "64/64 [==============================] - 4s 64ms/step - loss: 7.7087e-04 - val_loss: 0.0014\n",
            "Epoch 85/100\n",
            "64/64 [==============================] - 4s 63ms/step - loss: 9.1919e-04 - val_loss: 6.9968e-04\n",
            "Epoch 86/100\n",
            "64/64 [==============================] - 4s 63ms/step - loss: 6.5578e-04 - val_loss: 8.9062e-04\n",
            "Epoch 87/100\n",
            "64/64 [==============================] - 4s 63ms/step - loss: 5.8687e-04 - val_loss: 6.2908e-04\n",
            "Epoch 88/100\n",
            "64/64 [==============================] - 4s 64ms/step - loss: 5.9082e-04 - val_loss: 8.5307e-04\n",
            "Epoch 89/100\n",
            "64/64 [==============================] - 4s 65ms/step - loss: 5.7080e-04 - val_loss: 4.9355e-04\n",
            "Epoch 90/100\n",
            "64/64 [==============================] - 4s 64ms/step - loss: 5.1046e-04 - val_loss: 8.9495e-04\n",
            "Epoch 91/100\n",
            "64/64 [==============================] - 4s 63ms/step - loss: 6.1694e-04 - val_loss: 7.8973e-04\n",
            "Epoch 92/100\n",
            "64/64 [==============================] - 4s 63ms/step - loss: 0.0010 - val_loss: 0.0014\n",
            "Epoch 93/100\n",
            "64/64 [==============================] - 4s 64ms/step - loss: 7.0245e-04 - val_loss: 4.5458e-04\n",
            "Epoch 94/100\n",
            "64/64 [==============================] - 4s 65ms/step - loss: 4.3110e-04 - val_loss: 4.3469e-04\n",
            "Epoch 95/100\n",
            "64/64 [==============================] - 4s 63ms/step - loss: 5.4301e-04 - val_loss: 4.7805e-04\n",
            "Epoch 96/100\n",
            "64/64 [==============================] - 4s 64ms/step - loss: 5.8348e-04 - val_loss: 4.5085e-04\n",
            "Epoch 97/100\n",
            "64/64 [==============================] - 4s 63ms/step - loss: 9.0008e-04 - val_loss: 0.0012\n",
            "Epoch 98/100\n",
            "64/64 [==============================] - 4s 63ms/step - loss: 4.8834e-04 - val_loss: 5.3956e-04\n",
            "Epoch 99/100\n",
            "64/64 [==============================] - 4s 63ms/step - loss: 4.6578e-04 - val_loss: 5.8891e-04\n",
            "Epoch 100/100\n",
            "64/64 [==============================] - 4s 63ms/step - loss: 5.9094e-04 - val_loss: 4.1725e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJSlA-z7NRHE",
        "outputId": "43734aca-c1f8-4e99-89c5-2158382104a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "# 7.13 LSTM 네트워크 학습 결과 확인\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['loss'], 'b-', label='loss')\n",
        "plt.plot(history.history['val_loss'], 'r--', label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ob1VbaYzJCWa",
        "outputId": "b0c4d7cc-5074-4d70-c0ef-5a1d585f8854",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 7.14 Test 데이터에 대한 예측 정확도 확인\n",
        "model.evaluate(X[2560:], Y[2560:])\n",
        "prediction = model.predict(X[2560:2560+5])\n",
        "for i in range(5):\n",
        "    print(Y[2560+i], '\\t', prediction[i][0], '\\tdiff:', abs(prediction[i][0] - Y[2560+i]))\n",
        "    \n",
        "prediction = model.predict(X[2560:])\n",
        "cnt = 0\n",
        "for i in range(len(prediction)):\n",
        "    if abs(prediction[i][0] - Y[2560+i]) > 0.04:\n",
        "        cnt += 1\n",
        "print('correctness:', (440 - cnt) / 440 * 100, '%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14/14 [==============================] - 1s 21ms/step - loss: 3.6632e-04\n",
            "1/1 [==============================] - 1s 789ms/step\n",
            "0.1162097578656399 \t 0.14598909 \tdiff: 0.029779332338598988\n",
            "0.19848398653168728 \t 0.19867322 \tdiff: 0.00018923195700595863\n",
            "0.05628569993520576 \t 0.058790404 \tdiff: 0.0025047044143597444\n",
            "0.03480691558825324 \t 0.06369543 \tdiff: 0.028888515167361996\n",
            "0.022800598289235353 \t 0.029333517 \tdiff: 0.006532918666140319\n",
            "14/14 [==============================] - 0s 20ms/step\n",
            "correctness: 95.68181818181817 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxV7T14AvXkH"
      },
      "source": [
        "## 7.2.3 GRU 레이어"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WjH-A0WvNAO",
        "outputId": "e3160d4b-43f6-47c9-9360-7398b0746d8b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 7.15 GRU 레이어를 사용한 곱셈 문제 모델 정의\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.GRU(units=30, return_sequences=True, input_shape=[100,2]),\n",
        "    tf.keras.layers.GRU(units=30),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru (GRU)                   (None, 100, 30)           3060      \n",
            "                                                                 \n",
            " gru_1 (GRU)                 (None, 30)                5580      \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 31        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,671\n",
            "Trainable params: 8,671\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vd6C4gvUvdQS",
        "outputId": "98747931-09af-4b24-dd1e-39ba6a7a3aea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 7.16 GRU 네트워크 학습\n",
        "X = np.array(X)\n",
        "Y = np.array(Y)\n",
        "history = model.fit(X[:2560], Y[:2560], epochs=100, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "64/64 [==============================] - 7s 20ms/step - loss: 0.0492 - val_loss: 0.0533\n",
            "Epoch 2/100\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0480 - val_loss: 0.0529\n",
            "Epoch 3/100\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0469 - val_loss: 0.0530\n",
            "Epoch 4/100\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0470 - val_loss: 0.0523\n",
            "Epoch 5/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0478 - val_loss: 0.0522\n",
            "Epoch 6/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0467 - val_loss: 0.0522\n",
            "Epoch 7/100\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0469 - val_loss: 0.0524\n",
            "Epoch 8/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0472 - val_loss: 0.0520\n",
            "Epoch 9/100\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0466 - val_loss: 0.0517\n",
            "Epoch 10/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0467 - val_loss: 0.0531\n",
            "Epoch 11/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0471 - val_loss: 0.0516\n",
            "Epoch 12/100\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0463 - val_loss: 0.0534\n",
            "Epoch 13/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0465 - val_loss: 0.0520\n",
            "Epoch 14/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0465 - val_loss: 0.0536\n",
            "Epoch 15/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0471 - val_loss: 0.0512\n",
            "Epoch 16/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0460 - val_loss: 0.0511\n",
            "Epoch 17/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0454 - val_loss: 0.0501\n",
            "Epoch 18/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0451 - val_loss: 0.0497\n",
            "Epoch 19/100\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0416 - val_loss: 0.0418\n",
            "Epoch 20/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0234 - val_loss: 0.0104\n",
            "Epoch 21/100\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0040 - val_loss: 0.0035\n",
            "Epoch 22/100\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0023 - val_loss: 0.0027\n",
            "Epoch 23/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0019 - val_loss: 0.0028\n",
            "Epoch 24/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0016 - val_loss: 0.0018\n",
            "Epoch 25/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 0.0018\n",
            "Epoch 26/100\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0016 - val_loss: 0.0020\n",
            "Epoch 27/100\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 9.7754e-04 - val_loss: 0.0012\n",
            "Epoch 28/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 8.4951e-04 - val_loss: 9.7690e-04\n",
            "Epoch 29/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 7.3303e-04 - val_loss: 0.0011\n",
            "Epoch 30/100\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 6.7622e-04 - val_loss: 7.9590e-04\n",
            "Epoch 31/100\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 6.7664e-04 - val_loss: 8.1843e-04\n",
            "Epoch 32/100\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 6.2517e-04 - val_loss: 9.7953e-04\n",
            "Epoch 33/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 5.6076e-04 - val_loss: 7.3944e-04\n",
            "Epoch 34/100\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 5.5561e-04 - val_loss: 7.4110e-04\n",
            "Epoch 35/100\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 5.1623e-04 - val_loss: 6.8004e-04\n",
            "Epoch 36/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 4.8041e-04 - val_loss: 7.5484e-04\n",
            "Epoch 37/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 4.9334e-04 - val_loss: 8.2303e-04\n",
            "Epoch 38/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 5.0223e-04 - val_loss: 5.8346e-04\n",
            "Epoch 39/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 4.6021e-04 - val_loss: 7.7287e-04\n",
            "Epoch 40/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 4.0575e-04 - val_loss: 7.2112e-04\n",
            "Epoch 41/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 4.1880e-04 - val_loss: 6.2198e-04\n",
            "Epoch 42/100\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 4.0310e-04 - val_loss: 7.5133e-04\n",
            "Epoch 43/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 3.6562e-04 - val_loss: 6.0479e-04\n",
            "Epoch 44/100\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 4.2675e-04 - val_loss: 5.1552e-04\n",
            "Epoch 45/100\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 3.6101e-04 - val_loss: 5.3273e-04\n",
            "Epoch 46/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 4.4938e-04 - val_loss: 5.3302e-04\n",
            "Epoch 47/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 3.2276e-04 - val_loss: 5.1039e-04\n",
            "Epoch 48/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 3.2190e-04 - val_loss: 4.5103e-04\n",
            "Epoch 49/100\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 3.1438e-04 - val_loss: 4.6253e-04\n",
            "Epoch 50/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 2.8947e-04 - val_loss: 5.4149e-04\n",
            "Epoch 51/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 2.8179e-04 - val_loss: 5.0983e-04\n",
            "Epoch 52/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 2.8581e-04 - val_loss: 4.0339e-04\n",
            "Epoch 53/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 2.9107e-04 - val_loss: 4.2242e-04\n",
            "Epoch 54/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 2.9419e-04 - val_loss: 4.1271e-04\n",
            "Epoch 55/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 3.1065e-04 - val_loss: 4.2995e-04\n",
            "Epoch 56/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 2.8222e-04 - val_loss: 3.8426e-04\n",
            "Epoch 57/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 3.3566e-04 - val_loss: 9.6252e-04\n",
            "Epoch 58/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 3.4257e-04 - val_loss: 4.8930e-04\n",
            "Epoch 59/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 3.9137e-04 - val_loss: 4.2346e-04\n",
            "Epoch 60/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 2.4983e-04 - val_loss: 5.6752e-04\n",
            "Epoch 61/100\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 2.4345e-04 - val_loss: 5.0651e-04\n",
            "Epoch 62/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 2.1702e-04 - val_loss: 3.5207e-04\n",
            "Epoch 63/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 3.3638e-04 - val_loss: 3.3667e-04\n",
            "Epoch 64/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 2.0957e-04 - val_loss: 3.2251e-04\n",
            "Epoch 65/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 1.9615e-04 - val_loss: 3.5446e-04\n",
            "Epoch 66/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 1.9275e-04 - val_loss: 3.0840e-04\n",
            "Epoch 67/100\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 2.1840e-04 - val_loss: 4.0037e-04\n",
            "Epoch 68/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 2.2091e-04 - val_loss: 3.3924e-04\n",
            "Epoch 69/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 3.1950e-04 - val_loss: 3.8999e-04\n",
            "Epoch 70/100\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 1.9285e-04 - val_loss: 2.8326e-04\n",
            "Epoch 71/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 1.6125e-04 - val_loss: 2.8625e-04\n",
            "Epoch 72/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 2.2374e-04 - val_loss: 2.9073e-04\n",
            "Epoch 73/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 1.6777e-04 - val_loss: 3.3914e-04\n",
            "Epoch 74/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 1.6482e-04 - val_loss: 4.1503e-04\n",
            "Epoch 75/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 2.1213e-04 - val_loss: 2.4565e-04\n",
            "Epoch 76/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 1.7567e-04 - val_loss: 2.6883e-04\n",
            "Epoch 77/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 1.5044e-04 - val_loss: 4.8813e-04\n",
            "Epoch 78/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 1.6641e-04 - val_loss: 2.7252e-04\n",
            "Epoch 79/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 1.6975e-04 - val_loss: 2.4746e-04\n",
            "Epoch 80/100\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 2.6127e-04 - val_loss: 2.4375e-04\n",
            "Epoch 81/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 1.7803e-04 - val_loss: 3.9416e-04\n",
            "Epoch 82/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 1.5486e-04 - val_loss: 2.8125e-04\n",
            "Epoch 83/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 1.3751e-04 - val_loss: 2.3177e-04\n",
            "Epoch 84/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 1.5262e-04 - val_loss: 2.7185e-04\n",
            "Epoch 85/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 1.6215e-04 - val_loss: 2.0682e-04\n",
            "Epoch 86/100\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 1.6942e-04 - val_loss: 4.3432e-04\n",
            "Epoch 87/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 1.7960e-04 - val_loss: 2.8696e-04\n",
            "Epoch 88/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 1.2145e-04 - val_loss: 2.2121e-04\n",
            "Epoch 89/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 1.1303e-04 - val_loss: 1.7678e-04\n",
            "Epoch 90/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 1.1046e-04 - val_loss: 2.0574e-04\n",
            "Epoch 91/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 1.2636e-04 - val_loss: 1.7036e-04\n",
            "Epoch 92/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 1.2278e-04 - val_loss: 1.6500e-04\n",
            "Epoch 93/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 1.4692e-04 - val_loss: 2.1487e-04\n",
            "Epoch 94/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 1.1934e-04 - val_loss: 1.9713e-04\n",
            "Epoch 95/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 1.6613e-04 - val_loss: 2.4924e-04\n",
            "Epoch 96/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 1.1935e-04 - val_loss: 1.8541e-04\n",
            "Epoch 97/100\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 9.3419e-05 - val_loss: 2.0881e-04\n",
            "Epoch 98/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 8.8197e-05 - val_loss: 1.5200e-04\n",
            "Epoch 99/100\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 1.1816e-04 - val_loss: 1.8969e-04\n",
            "Epoch 100/100\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 1.2431e-04 - val_loss: 1.7673e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SHz_LHExkH3",
        "outputId": "a7dab3cf-b3bc-40c0-c860-5552d1cc7c82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "# 7.17 GRU 네트워크 학습 결과 확인\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['loss'], 'b-', label='loss')\n",
        "plt.plot(history.history['val_loss'], 'r--', label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdecdSb0xkDj",
        "outputId": "7cda9cf0-d76a-4b2c-b8ea-95e3b39d8413",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 7.18 Test 데이터에 대한 예측 정확도 확인\n",
        "model.evaluate(X[2560:], Y[2560:])\n",
        "prediction = model.predict(X[2560:2560+5])\n",
        "for i in range(5):\n",
        "    print(Y[2560+i], '\\t', prediction[i][0], '\\tdiff:', abs(prediction[i][0] - Y[2560+i]))\n",
        "    \n",
        "prediction = model.predict(X[2560:])\n",
        "cnt = 0\n",
        "for i in range(len(prediction)):\n",
        "    if abs(prediction[i][0] - Y[2560+i]) > 0.04:\n",
        "        cnt += 1\n",
        "print('correctness:', (440 - cnt) / 440 * 100, '%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14/14 [==============================] - 1s 9ms/step - loss: 1.3471e-04\n",
            "0.38300888141964545 \t 0.38484603 \tdiff: 0.0018371502461565492\n",
            "0.23104388718279487 \t 0.2346411 \tdiff: 0.0035972177538048655\n",
            "0.09707748182332913 \t 0.10267833 \tdiff: 0.005600846929188566\n",
            "0.48207583355785905 \t 0.47980088 \tdiff: 0.002274953602567298\n",
            "0.4072524087138894 \t 0.41243958 \tdiff: 0.005187176018166262\n",
            "correctness: 98.18181818181819 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4rFl018T7Py"
      },
      "source": [
        "# 7.3 긍정, 부정 감성 분석"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srjpifEqUAx3",
        "outputId": "43f4b097-36bd-4a86-aa17-10dcc182265f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 7.19 Naver Sentiment Movie Corpus v1.0 다운로드\n",
        "path_to_train_file = tf.keras.utils.get_file('train.txt', 'https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt')\n",
        "path_to_test_file = tf.keras.utils.get_file('test.txt', 'https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt\n",
            "14628807/14628807 [==============================] - 0s 0us/step\n",
            "Downloading data from https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt\n",
            "4893335/4893335 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8e3_cWrjcZ8X",
        "outputId": "89870f2d-2fad-4364-8ad4-5c600189102e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 7.20 데이터 로드 및 확인\n",
        "# 데이터를 메모리에 불러옵니다. encoding 형식으로 utf-8 을 지정해야합니다.\n",
        "train_text = open(path_to_train_file, 'rb').read().decode(encoding='utf-8')\n",
        "test_text = open(path_to_test_file, 'rb').read().decode(encoding='utf-8')\n",
        "\n",
        "# 텍스트가 총 몇 자인지 확인합니다.\n",
        "print('Length of text: {} characters'.format(len(train_text)))\n",
        "print('Length of text: {} characters'.format(len(test_text)))\n",
        "print()\n",
        "\n",
        "# 처음 300 자를 확인해봅니다.\n",
        "print(train_text[:300])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of text: 6937271 characters\n",
            "Length of text: 2318260 characters\n",
            "\n",
            "id\tdocument\tlabel\n",
            "9976970\t아 더빙.. 진짜 짜증나네요 목소리\t0\n",
            "3819312\t흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나\t1\n",
            "10265843\t너무재밓었다그래서보는것을추천한다\t0\n",
            "9045019\t교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정\t0\n",
            "6483659\t사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 던스트가 너무나도 이뻐보였다\t1\n",
            "5403919\t막 걸음마 뗀 3세부터 초등학교 1학년생인 8살용영화.ㅋㅋㅋ...별반개도 아까움.\t0\n",
            "7797314\t원작의\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3R4G9NAekYsE",
        "outputId": "42c9d32a-c5a2-48e9-f393-7be3581b9563",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 7.21 학습을 위한 정답 데이터(Y) 만들기\n",
        "train_Y = np.array([[int(row.split('\\t')[2])] for row in train_text.split('\\n')[1:] if row.count('\\t') > 0])\n",
        "test_Y = np.array([[int(row.split('\\t')[2])] for row in test_text.split('\\n')[1:] if row.count('\\t') > 0])\n",
        "print(train_Y.shape, test_Y.shape)\n",
        "print(train_Y[:5])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(150000, 1) (50000, 1)\n",
            "[[0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlrwaPyJ06V5",
        "outputId": "e79e82e6-a05b-4fc6-e864-387c1267a6d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 7.22 train 데이터의 입력(X)에 대한 정제(Cleaning)\n",
        "import re\n",
        "# From https://github.com/yoonkim/CNN_sentence/blob/master/process_data.py\n",
        "def clean_str(string):    \n",
        "    string = re.sub(r\"[^가-힣A-Za-z0-9(),!?\\'\\`]\", \" \", string)\n",
        "    string = re.sub(r\"\\'s\", \" \\'s\", string)\n",
        "    string = re.sub(r\"\\'ve\", \" \\'ve\", string)\n",
        "    string = re.sub(r\"n\\'t\", \" n\\'t\", string)\n",
        "    string = re.sub(r\"\\'re\", \" \\'re\", string)\n",
        "    string = re.sub(r\"\\'d\", \" \\'d\", string)\n",
        "    string = re.sub(r\"\\'ll\", \" \\'ll\", string)\n",
        "    string = re.sub(r\",\", \" , \", string)\n",
        "    string = re.sub(r\"!\", \" ! \", string)\n",
        "    string = re.sub(r\"\\(\", \" \\( \", string)\n",
        "    string = re.sub(r\"\\)\", \" \\) \", string)\n",
        "    string = re.sub(r\"\\?\", \" \\? \", string)\n",
        "    string = re.sub(r\"\\s{2,}\", \" \", string)\n",
        "    string = re.sub(r\"\\'{2,}\", \"\\'\", string)\n",
        "    string = re.sub(r\"\\'\", \"\", string)\n",
        "\n",
        "    return string.lower()\n",
        "\n",
        "\n",
        "train_text_X = [row.split('\\t')[1] for row in train_text.split('\\n')[1:] if row.count('\\t') > 0]\n",
        "train_text_X = [clean_str(sentence) for sentence in train_text_X]\n",
        "# 문장을 띄어쓰기 단위로 단어 분리\n",
        "sentences = [sentence.split(' ') for sentence in train_text_X]\n",
        "for i in range(5):\n",
        "    print(sentences[i])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['아', '더빙', '진짜', '짜증나네요', '목소리']\n",
            "['흠', '포스터보고', '초딩영화줄', '오버연기조차', '가볍지', '않구나']\n",
            "['너무재밓었다그래서보는것을추천한다']\n",
            "['교도소', '이야기구먼', '솔직히', '재미는', '없다', '평점', '조정']\n",
            "['사이몬페그의', '익살스런', '연기가', '돋보였던', '영화', '!', '스파이더맨에서', '늙어보이기만', '했던', '커스틴', '던스트가', '너무나도', '이뻐보였다']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwtf77CE0xPi",
        "outputId": "2652a4b5-0ca5-407c-d2b8-46e700c880cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "# 7.23 각 문장의 단어 길이 확인\n",
        "import matplotlib.pyplot as plt\n",
        "sentence_len = [len(sentence) for sentence in sentences]\n",
        "sentence_len.sort()\n",
        "plt.plot(sentence_len)\n",
        "plt.show()\n",
        "\n",
        "print(sum([int(l<=25) for l in sentence_len]))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "142587\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9F0OQSB71Az",
        "outputId": "e4a50618-5a2b-4cb5-d583-4540e60070ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 7.24 단어 정제 및 문장 길이 줄임\n",
        "sentences_new = []\n",
        "for sentence in sentences:\n",
        "    sentences_new.append([word[:5] for word in sentence][:25])\n",
        "sentences = sentences_new\n",
        "for i in range(5):\n",
        "    print(sentences[i])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['아', '더빙', '진짜', '짜증나네요', '목소리']\n",
            "['흠', '포스터보고', '초딩영화줄', '오버연기조', '가볍지', '않구나']\n",
            "['너무재밓었']\n",
            "['교도소', '이야기구먼', '솔직히', '재미는', '없다', '평점', '조정']\n",
            "['사이몬페그', '익살스런', '연기가', '돋보였던', '영화', '!', '스파이더맨', '늙어보이기', '했던', '커스틴', '던스트가', '너무나도', '이뻐보였다']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iHRApH_SxJz",
        "outputId": "e55ca53c-1918-4715-d316-7e5bb5abcc5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 7.25 Tokenizer와 pad_sequences를 사용한 문장 전처리\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "tokenizer = Tokenizer(num_words=20000)\n",
        "tokenizer.fit_on_texts(sentences) # 각 단어들에 대해서 매칭되는 숫자\n",
        "train_X = tokenizer.texts_to_sequences(sentences) #sentences를 순서대로 집어넣음\n",
        "train_X = pad_sequences(train_X, padding='post')  # padding은 0을 집어넣음\n",
        "\n",
        "print(train_X[:5])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[   25   884     8  5795  1111     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0]\n",
            " [  588  5796  6697     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0]\n",
            " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0]\n",
            " [   71   346    31    35 10468     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0]\n",
            " [  106  5338     4     2  2169   869   573     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Id3SzN7350CB",
        "outputId": "b6e6dcb0-1901-4ba6-8c74-bc90309dc9fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 7.26 Tokenizer의 동작 확인\n",
        "print(tokenizer.index_word[19999])\n",
        "print(tokenizer.index_word[20000])\n",
        "temp = tokenizer.texts_to_sequences(['#$#$#', '경우는', '잊혀질', '연기가'])\n",
        "print(temp)\n",
        "temp = pad_sequences(temp, padding='post')\n",
        "print(temp)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "경우는\n",
            "잊혀질\n",
            "[[], [19999], [], [106]]\n",
            "[[    0]\n",
            " [19999]\n",
            " [    0]\n",
            " [  106]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHkCAL4QpVAF",
        "outputId": "f62b47fc-663b-4e69-e268-6c9efc9deeee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 7.27 감성 분석을 위한 모델 정의\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(20000, 300, input_length=25),\n",
        "    tf.keras.layers.LSTM(units=50),\n",
        "    tf.keras.layers.Dense(2, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 25, 300)           6000000   \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 50)                70200     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 102       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6,070,302\n",
            "Trainable params: 6,070,302\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DG5bZtehpU8O",
        "outputId": "ca372738-f4b3-453d-a766-d29bae207f18",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 7.28 감성 분석 모델 학습\n",
        "history = model.fit(train_X, train_Y, epochs=5, batch_size=128, validation_split=0.2)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "938/938 [==============================] - 14s 9ms/step - loss: 0.4329 - accuracy: 0.7863 - val_loss: 0.3780 - val_accuracy: 0.8217\n",
            "Epoch 2/5\n",
            "938/938 [==============================] - 8s 8ms/step - loss: 0.3243 - accuracy: 0.8475 - val_loss: 0.3921 - val_accuracy: 0.8199\n",
            "Epoch 3/5\n",
            "938/938 [==============================] - 8s 8ms/step - loss: 0.2709 - accuracy: 0.8688 - val_loss: 0.4047 - val_accuracy: 0.8173\n",
            "Epoch 4/5\n",
            "938/938 [==============================] - 8s 8ms/step - loss: 0.2275 - accuracy: 0.8889 - val_loss: 0.4959 - val_accuracy: 0.8134\n",
            "Epoch 5/5\n",
            "938/938 [==============================] - 9s 9ms/step - loss: 0.1939 - accuracy: 0.9053 - val_loss: 0.6010 - val_accuracy: 0.8080\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-N83MOKFpU4a",
        "outputId": "5205bca0-471f-4ae9-d555-2ad64ea27b19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "# 7.29 감성 분석 모델 학습 결과 확인\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], 'b-', label='loss')\n",
        "plt.plot(history.history['val_loss'], 'r--', label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['accuracy'], 'g-', label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], 'k--', label='val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylim(0.7, 1)\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dS4Bw55e1HQa",
        "outputId": "88eb8a91-1ee3-45dc-b560-e1644b28f1ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 7.30 테스트 데이터 평가\n",
        "test_text_X = [row.split('\\t')[1] for row in test_text.split('\\n')[1:] if row.count('\\t') > 0]\n",
        "test_text_X = [clean_str(sentence) for sentence in test_text_X]\n",
        "sentences = [sentence.split(' ') for sentence in test_text_X]\n",
        "sentences_new = []\n",
        "for sentence in sentences:\n",
        "    sentences_new.append([word[:5] for word in sentence][:25])\n",
        "sentences = sentences_new\n",
        "\n",
        "test_X = tokenizer.texts_to_sequences(sentences)  # 텍스트 단어를 숫자로 바꿔줌\n",
        "test_X = pad_sequences(test_X, padding='post')\n",
        "\n",
        "model.evaluate(test_X, test_Y, verbose=0)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6079968214035034, 0.8009200096130371]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_gWAXeb1HM0",
        "outputId": "5f7885c2-61a1-4fcf-e740-cbc38aaafafa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 7.31 임의의 문장 감성 분석 결과 확인\n",
        "test_sentence = '재미있을 줄 알았는데 완전 실망했다. 너무 졸리고 돈이 아까웠다.'\n",
        "test_sentence = test_sentence.split(' ')\n",
        "test_sentences = []\n",
        "now_sentence = []\n",
        "for word in test_sentence:\n",
        "    now_sentence.append(word)\n",
        "    test_sentences.append(now_sentence[:])\n",
        "    \n",
        "test_X_1 = tokenizer.texts_to_sequences(test_sentences)\n",
        "test_X_1 = pad_sequences(test_X_1, padding='post', maxlen=25)\n",
        "prediction = model.predict(test_X_1)\n",
        "for idx, sentence in enumerate(test_sentences):\n",
        "    print(sentence)\n",
        "    print(prediction[idx])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 335ms/step\n",
            "['재미있을']\n",
            "[0.44505492 0.5549451 ]\n",
            "['재미있을', '줄']\n",
            "[0.37494272 0.62505734]\n",
            "['재미있을', '줄', '알았는데']\n",
            "[0.40838543 0.59161454]\n",
            "['재미있을', '줄', '알았는데', '완전']\n",
            "[0.47137326 0.5286267 ]\n",
            "['재미있을', '줄', '알았는데', '완전', '실망했다.']\n",
            "[0.47137326 0.5286267 ]\n",
            "['재미있을', '줄', '알았는데', '완전', '실망했다.', '너무']\n",
            "[0.66250956 0.33749044]\n",
            "['재미있을', '줄', '알았는데', '완전', '실망했다.', '너무', '졸리고']\n",
            "[0.9982363  0.00176373]\n",
            "['재미있을', '줄', '알았는데', '완전', '실망했다.', '너무', '졸리고', '돈이']\n",
            "[9.9905163e-01 9.4837556e-04]\n",
            "['재미있을', '줄', '알았는데', '완전', '실망했다.', '너무', '졸리고', '돈이', '아까웠다.']\n",
            "[9.9905163e-01 9.4837556e-04]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbJuXY19T-vd"
      },
      "source": [
        "# 7.4 자연어 생성"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3eau9dNxOgR"
      },
      "source": [
        "## 7.4.1 단어 단위 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWbhqXUTUBJj",
        "outputId": "227b985a-4784-4df3-fd2e-f10f1ce0d51a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 7.32 조선왕조실록 데이터 파일 다운로드\n",
        "path_to_file = tf.keras.utils.get_file('input.txt', 'http://bit.ly/2Mc3SOV')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from http://bit.ly/2Mc3SOV\n",
            "62012502/62012502 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uFbN0cwulLE",
        "outputId": "419c6d18-51b3-4b8a-d8ca-ca1ac9612f38",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 7.33 데이터 로드 및 확인\n",
        "# 데이터를 메모리에 불러옵니다. encoding 형식으로 utf-8 을 지정해야합니다.\n",
        "train_text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "\n",
        "# 텍스트가 총 몇 자인지 확인합니다.\n",
        "print('Length of text: {} characters'.format(len(train_text)))\n",
        "print()\n",
        "\n",
        "# 처음 100 자를 확인해봅니다.\n",
        "print(train_text[:100])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of text: 26265493 characters\n",
            "\n",
            "﻿태조 이성계 선대의 가계. 목조 이안사가 전주에서 삼척·의주를 거쳐 알동에 정착하다 \n",
            "태조 강헌 지인 계운 성문 신무 대왕(太祖康獻至仁啓運聖文神武大王)의 성은 이씨(李氏)요, 휘\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYpvgEtfulIe",
        "outputId": "c6b5b874-a4eb-4243-e619-fe2cc421b378",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 7.34 훈련 데이터 입력 정제\n",
        "import re\n",
        "# From https://github.com/yoonkim/CNN_sentence/blob/master/process_data.py\n",
        "def clean_str(string):    \n",
        "    string = re.sub(r\"[^가-힣A-Za-z0-9(),!?\\'\\`]\", \" \", string)\n",
        "    string = re.sub(r\"\\'ll\", \" \\'ll\", string)\n",
        "    string = re.sub(r\",\", \" , \", string)\n",
        "    string = re.sub(r\"!\", \" ! \", string)\n",
        "    string = re.sub(r\"\\(\", \"\", string)\n",
        "    string = re.sub(r\"\\)\", \"\", string)\n",
        "    string = re.sub(r\"\\?\", \" \\? \", string)\n",
        "    string = re.sub(r\"\\s{2,}\", \" \", string)\n",
        "    string = re.sub(r\"\\'{2,}\", \"\\'\", string)\n",
        "    string = re.sub(r\"\\'\", \"\", string)\n",
        "\n",
        "    return string\n",
        "\n",
        "\n",
        "train_text = train_text.split('\\n')\n",
        "train_text = [clean_str(sentence) for sentence in train_text]\n",
        "train_text_X = []\n",
        "for sentence in train_text:\n",
        "    train_text_X.extend(sentence.split(' '))\n",
        "    train_text_X.append('\\n')\n",
        "    \n",
        "train_text_X = [word for word in train_text_X if word != '']\n",
        "\n",
        "print(train_text_X[:20])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['태조', '이성계', '선대의', '가계', '목조', '이안사가', '전주에서', '삼척', '의주를', '거쳐', '알동에', '정착하다', '\\n', '태조', '강헌', '지인', '계운', '성문', '신무', '대왕']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWMq4C-qulCn",
        "outputId": "806ecba3-1f19-48e5-c962-06a126c6151c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 7.35 단어 토큰화\n",
        "# 단어의 set을 만듭니다.\n",
        "vocab = sorted(set(train_text_X))\n",
        "vocab.append('UNK')\n",
        "print ('{} unique words'.format(len(vocab)))\n",
        "\n",
        "# vocab list를 숫자로 맵핑하고, 반대도 실행합니다.\n",
        "word2idx = {u:i for i, u in enumerate(vocab)}\n",
        "idx2word = np.array(vocab)\n",
        "\n",
        "text_as_int = np.array([word2idx[c] for c in train_text_X])\n",
        "\n",
        "# word2idx 의 일부를 알아보기 쉽게 print 해봅니다.\n",
        "print('{')\n",
        "for word,_ in zip(word2idx, range(10)):\n",
        "    print('  {:4s}: {:3d},'.format(repr(word), word2idx[word]))\n",
        "print('  ...\\n}')\n",
        "\n",
        "print('index of UNK: {}'.format(word2idx['UNK']))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "332640 unique words\n",
            "{\n",
            "  '\\n':   0,\n",
            "  '!' :   1,\n",
            "  ',' :   2,\n",
            "  '000명으로':   3,\n",
            "  '001':   4,\n",
            "  '002':   5,\n",
            "  '003':   6,\n",
            "  '004':   7,\n",
            "  '005':   8,\n",
            "  '006':   9,\n",
            "  ...\n",
            "}\n",
            "index of UNK: 332639\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIOkvMpd_7Wd",
        "outputId": "a516ce70-b92a-47b0-be62-f910f6ed6a96",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 7.36 토큰 데이터 확인\n",
        "print(train_text_X[:20])\n",
        "print(text_as_int[:20])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['태조', '이성계', '선대의', '가계', '목조', '이안사가', '전주에서', '삼척', '의주를', '거쳐', '알동에', '정착하다', '\\n', '태조', '강헌', '지인', '계운', '성문', '신무', '대왕']\n",
            "[299305 229634 161443  17430 111029 230292 251081 155087 225462  29027\n",
            " 190295 256129      0 299305  25624 273553  36147 163996 180466  84413]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKeZRJsM_7Tx",
        "outputId": "bc3c15f5-317f-40f4-870c-282b268af0b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 7.37 기본 데이터셋 만들기\n",
        "seq_length = 25\n",
        "examples_per_epoch = len(text_as_int) // seq_length\n",
        "sentence_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
        "\n",
        "sentence_dataset = sentence_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "for item in sentence_dataset.take(1):\n",
        "    print(idx2word[item.numpy()])\n",
        "    print(item.numpy())"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['태조' '이성계' '선대의' '가계' '목조' '이안사가' '전주에서' '삼척' '의주를' '거쳐' '알동에' '정착하다'\n",
            " '\\n' '태조' '강헌' '지인' '계운' '성문' '신무' '대왕' '의' '성은' '이씨' '요' ',' '휘']\n",
            "[299305 229634 161443  17430 111029 230292 251081 155087 225462  29027\n",
            " 190295 256129      0 299305  25624 273553  36147 163996 180466  84413\n",
            " 224182 164549 230248 210912      2 330313]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCgSGJTQ_7QH",
        "outputId": "9a44ece3-1b7d-45e0-8ff3-ceb34b271d77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 7.38 학습 데이터셋 만들기\n",
        "def split_input_target(chunk):\n",
        "    return [chunk[:-1], chunk[-1]]\n",
        "\n",
        "train_dataset = sentence_dataset.map(split_input_target)\n",
        "for x,y in train_dataset.take(1):\n",
        "    print(idx2word[x.numpy()])\n",
        "    print(x.numpy())\n",
        "    print(idx2word[y.numpy()])\n",
        "    print(y.numpy())"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['태조' '이성계' '선대의' '가계' '목조' '이안사가' '전주에서' '삼척' '의주를' '거쳐' '알동에' '정착하다'\n",
            " '\\n' '태조' '강헌' '지인' '계운' '성문' '신무' '대왕' '의' '성은' '이씨' '요' ',']\n",
            "[299305 229634 161443  17430 111029 230292 251081 155087 225462  29027\n",
            " 190295 256129      0 299305  25624 273553  36147 163996 180466  84413\n",
            " 224182 164549 230248 210912      2]\n",
            "휘\n",
            "330313\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6LSzyUgS72O"
      },
      "source": [
        "# 7.39 데이터셋 shuffle, batch 설정\n",
        "BATCH_SIZE = 512\n",
        "steps_per_epoch = examples_per_epoch // BATCH_SIZE\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGDQMKzZRz9k",
        "outputId": "0ef8a9aa-5581-42be-a1f1-21bd8c89baf3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 7.40 단어 단위 생성 모델 정의\n",
        "total_words = len(vocab)\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(total_words, 100, input_length=seq_length),\n",
        "    tf.keras.layers.LSTM(units=100, return_sequences=True),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.LSTM(units=100),\n",
        "    tf.keras.layers.Dense(total_words, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 25, 100)           33264000  \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 25, 100)           80400     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 25, 100)           0         \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 100)               80400     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 332640)            33596640  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 67,021,440\n",
            "Trainable params: 67,021,440\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCF1_hcARz6g",
        "outputId": "995e8971-d84a-48c4-9d8f-9ef93ba4d690",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# 7.41 단어 단위 생성 모델 학습\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "def testmodel(epoch, logs):\n",
        "    if epoch % 5 != 0 and epoch != 49:\n",
        "        return\n",
        "    test_sentence = train_text[0]\n",
        "\n",
        "    next_words = 100\n",
        "    for _ in range(next_words):\n",
        "        test_text_X = test_sentence.split(' ')[-seq_length:]\n",
        "        test_text_X = np.array([word2idx[c] if c in word2idx else word2idx['UNK'] for c in test_text_X])\n",
        "        test_text_X = pad_sequences([test_text_X], maxlen=seq_length, padding='pre', value=word2idx['UNK'])\n",
        "\n",
        "        #output_idx = model.predict_classes(test_text_X)\n",
        "        output_idx_new = model.predict(test_text_X)\n",
        "        output_idx = output_idx_new.argmax(axis = -1)\n",
        "        test_sentence += ' ' + idx2word[output_idx[0]]\n",
        "    \n",
        "    print()\n",
        "    print(test_sentence)\n",
        "    print()\n",
        "\n",
        "testmodelcb = tf.keras.callbacks.LambdaCallback(on_epoch_end=testmodel)\n",
        "\n",
        "history = model.fit(train_dataset.repeat(), epochs=50, steps_per_epoch=steps_per_epoch, callbacks=[testmodelcb], verbose=2)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1/1 [==============================] - 1s 595ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "\n",
            " 태조 이성계 선대의 가계 목조 이안사가 전주에서 삼척 의주를 거쳐 알동에 정착하다  , 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그 그\n",
            "\n",
            "533/533 - 149s - loss: 8.0756 - accuracy: 0.0810 - 149s/epoch - 280ms/step\n",
            "Epoch 2/50\n",
            "533/533 - 143s - loss: 7.8184 - accuracy: 0.0896 - 143s/epoch - 268ms/step\n",
            "Epoch 3/50\n",
            "533/533 - 143s - loss: 7.5774 - accuracy: 0.1010 - 143s/epoch - 268ms/step\n",
            "Epoch 4/50\n",
            "533/533 - 143s - loss: 7.3343 - accuracy: 0.1174 - 143s/epoch - 268ms/step\n",
            "Epoch 5/50\n",
            "533/533 - 142s - loss: 7.1059 - accuracy: 0.1306 - 142s/epoch - 267ms/step\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "\n",
            " 태조 이성계 선대의 가계 목조 이안사가 전주에서 삼척 의주를 거쳐 알동에 정착하다  , , 그 죄를 보내어 , 그 번 보내어 , 그 죄를 , 그 죄를 , \n",
            " 하였다 \n",
            " 하니 , 임금이 , \n",
            " 하니 , 임금이 그 죄를 보내어 , 그 번 보내어 , 그 번 보내어 , 그 번 보내어 , 그 죄를 , 그 죄를 , \n",
            " 하였다 임금이 말하기를 , \n",
            " 임금이 말하기를 , \n",
            " 임금이 말하기를 , \n",
            " 임금이 말하기를 , \n",
            " 임금이 말하기를 , \n",
            " 임금이 말하기를 , \n",
            " 임금이 말하기를 , \n",
            " 임금이 말하기를 , \n",
            " 임금이 말하기를 , \n",
            " 임금이 말하기를 , \n",
            " 임금이 말하기를 , \n",
            " 임금이 말하기를 , \n",
            " 임금이\n",
            "\n",
            "533/533 - 148s - loss: 6.8551 - accuracy: 0.1413 - 148s/epoch - 277ms/step\n",
            "Epoch 7/50\n",
            "533/533 - 143s - loss: 6.6119 - accuracy: 0.1525 - 143s/epoch - 268ms/step\n",
            "Epoch 8/50\n",
            "533/533 - 143s - loss: 6.3788 - accuracy: 0.1634 - 143s/epoch - 267ms/step\n",
            "Epoch 9/50\n",
            "533/533 - 142s - loss: 6.1607 - accuracy: 0.1753 - 142s/epoch - 267ms/step\n",
            "Epoch 10/50\n",
            "533/533 - 142s - loss: 5.9342 - accuracy: 0.1867 - 142s/epoch - 267ms/step\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "\n",
            " 태조 이성계 선대의 가계 목조 이안사가 전주에서 삼척 의주를 거쳐 알동에 정착하다  사조하니 할 것입니다 \n",
            " 하니 , 그대로 따랐다 임금이 말하기를 , \n",
            " 하니 , 그대로 따랐다 임금이 말하기를 , \n",
            " 하니 , 그대로 하였다 임금이 말하기를 , \n",
            " 황희 등이 아뢰기를 , \n",
            " 상참을 받고 , 임금이 아뢰기를 , \n",
            " 상참을 받고 , 임금이 말하기를 , \n",
            " 하니 , 임금이 말하기를 , \n",
            " 하니 , 임금이 말하기를 , \n",
            " 하니 , 임금이 말하기를 , \n",
            " 하니 , 임금이 말하기를 , \n",
            " 하니 , 임금이 말하기를 , \n",
            " 하니 , 임금이 말하기를 , \n",
            " 하니 , 임금이 말하기를 , \n",
            " 하니 , 임금이 말하기를 , \n",
            " 하니 , 임금이 말하기를 ,\n",
            "\n",
            "533/533 - 147s - loss: 5.7061 - accuracy: 0.1986 - 147s/epoch - 276ms/step\n",
            "Epoch 12/50\n",
            "533/533 - 142s - loss: 5.4884 - accuracy: 0.2108 - 142s/epoch - 267ms/step\n",
            "Epoch 13/50\n",
            "533/533 - 142s - loss: 5.2669 - accuracy: 0.2241 - 142s/epoch - 267ms/step\n",
            "Epoch 14/50\n",
            "533/533 - 142s - loss: 5.0529 - accuracy: 0.2371 - 142s/epoch - 267ms/step\n",
            "Epoch 15/50\n",
            "533/533 - 142s - loss: 4.8395 - accuracy: 0.2519 - 142s/epoch - 267ms/step\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "\n",
            " 태조 이성계 선대의 가계 목조 이안사가 전주에서 삼척 의주를 거쳐 알동에 정착하다  어려울 것이 없는 것입니다 또 그 뜻을 다 있는 것입니다 비록 그 일이 있는 의 의 일을 모두 여러 의 사람을 다 다 다 북향하여 한다 고 하였다 임금이 말하기를 , \n",
            " 이제 여러 일은 비록 일찍이 아뢰기를 , \n",
            " 함길도 도절제사 가 하여금 와서 가서 가서 아뢰라 \n",
            " 하였다 의정부에서 아뢰기를 , \n",
            " 함길도 도절제사 는 1이니 , 명년에 술잔으로 의논하겠다 \n",
            " 하였다 세자가 호조의 이름으로 윤차로 토의 에 의거하여 다투어 인도하여 살피도록 하다 \n",
            " 하니 , 임금이 말하기를 , \n",
            " 의정부에서 전지하기를 , \n",
            " 의정부에서 호조의 정문에 이르기를 , \n",
            " 1 듣자오니 , 왕비가 현의 1천 삼 수납하여\n",
            "\n",
            "533/533 - 147s - loss: 4.6289 - accuracy: 0.2666 - 147s/epoch - 276ms/step\n",
            "Epoch 17/50\n",
            "533/533 - 142s - loss: 4.4259 - accuracy: 0.2835 - 142s/epoch - 267ms/step\n",
            "Epoch 18/50\n",
            "533/533 - 143s - loss: 4.2255 - accuracy: 0.2996 - 143s/epoch - 267ms/step\n",
            "Epoch 19/50\n",
            "533/533 - 143s - loss: 4.0311 - accuracy: 0.3182 - 143s/epoch - 268ms/step\n",
            "Epoch 20/50\n",
            "533/533 - 142s - loss: 3.8417 - accuracy: 0.3388 - 142s/epoch - 267ms/step\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "\n",
            " 태조 이성계 선대의 가계 목조 이안사가 전주에서 삼척 의주를 거쳐 알동에 정착하다  10여 어려울 것이니 , 그 말을 놓고 , 이를 다 있다 하고 , 비록 이를 법이 일이 없는 것입니다 비록 이미 이를 가는 것은 아닙니다 그러나 나라의 아우 상제 를 겸하게 하소서 \n",
            " 하니 , 그대로 따랐다 강맹경이 앞서 명나라 정문 에 이르기를 , \n",
            " 평안도 관찰사 는 더불어 와서 토물을 바치다 \n",
            " 일본국 관찰사 현감 강순 등을 불러서 토물을 바쳤다 사간원에서 풍양 와 이철 과 상서 으로 하여금 스스로 내리다 \n",
            " 일본국 환관 제독 동부 자문 으로 조연 으로 삼았다 전지 하기를 , \n",
            " 일본국 상송포 소간 진남군 소경 이었다 회맹의 메마르다 공좌 상당히 절의를 일이니 , 청컨대 그\n",
            "\n",
            "533/533 - 148s - loss: 3.6584 - accuracy: 0.3613 - 148s/epoch - 277ms/step\n",
            "Epoch 22/50\n",
            "533/533 - 143s - loss: 3.4765 - accuracy: 0.3858 - 143s/epoch - 268ms/step\n",
            "Epoch 23/50\n",
            "533/533 - 143s - loss: 3.3046 - accuracy: 0.4112 - 143s/epoch - 267ms/step\n",
            "Epoch 24/50\n",
            "533/533 - 143s - loss: 3.1313 - accuracy: 0.4380 - 143s/epoch - 268ms/step\n",
            "Epoch 25/50\n",
            "533/533 - 143s - loss: 2.9694 - accuracy: 0.4640 - 143s/epoch - 267ms/step\n",
            "Epoch 26/50\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-0b2bf4db9cd5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mtestmodelcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLambdaCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtestmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtestmodelcb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1407\u001b[0m                 _r=1):\n\u001b[1;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2451\u001b[0m       (graph_function,\n\u001b[1;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2454\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1859\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1860\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1861\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    498\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zz6UCaidRz2b",
        "outputId": "484d36b1-5218-4dc9-d5f6-5392269d1ab5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "# 7.42 임의의 문장을 사용한 생성 결과 확인\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "test_sentence = '동헌에 나가 공무를 본 후 활 십오 순을 쏘았다'\n",
        "\n",
        "next_words = 100\n",
        "for _ in range(next_words):\n",
        "    test_text_X = test_sentence.split(' ')[-seq_length:]\n",
        "    test_text_X = np.array([word2idx[c] if c in word2idx else word2idx['UNK'] for c in test_text_X])\n",
        "    test_text_X = pad_sequences([test_text_X], maxlen=seq_length, padding='pre', value=word2idx['UNK'])\n",
        "    \n",
        "    output_idx = model.predict_classes(test_text_X)\n",
        "    test_sentence += ' ' + idx2word[output_idx[0]]\n",
        "\n",
        "print(test_sentence)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "동헌에 나가 공무를 본 후 활 십오 순을 쏘았다 그곳의 사로잡힌 대리하는 호군직 2개는 놓기도 토의 으로써 차임 되고 , 저들은 일시에 굳게 것으로서 주고 , 더욱 높은 바가 많아서 정위 라 같다 하는데 하였습니다 빈자 는 부의 에 도와서 알아야 하여 주소서 \n",
            " 하니 , 형조 에서 교지 를 하사하고 충청도 도절제사 에서 다시 와서 와서 내려 쓸 하고 , 만일 잘 가는 것이 없었다 상수의 대한 한 한 뒤에 모두 능히 서로 알지 것은 감히 모두 모두 모두 사람을 죄를 죄를 사람을 죄를 온 한 사람을 삼가서 어질고 그믐날에 한다는 것이니 , 청컨대 이러한 정성을 알아서 난 를 정하여 급히 원하는 곳에 두고 특별히 징계하여 인도해 특별히\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Hzr8inp0Go4"
      },
      "source": [
        "## 7.4.2 자소 단위 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPw8MxlxvE66",
        "outputId": "00536e8e-860c-4650-b717-8d4580f51b2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 7.43 jamotools 설치\n",
        "!pip install jamotools"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: jamotools in /usr/local/lib/python3.7/dist-packages (0.1.10)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from jamotools) (1.21.6)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from jamotools) (0.16.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from jamotools) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xq6XfbRpvEz5",
        "outputId": "07ea78a7-f869-48ea-f818-8620a27ba846",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 7.44 자모 분리 테스트\n",
        "import jamotools\n",
        "\n",
        "train_text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "s = train_text[:100]\n",
        "print(s)\n",
        "\n",
        "# 한글 텍스트를 자모 단위로 분리해줍니다. 한자 등에는 영향이 없습니다.\n",
        "s_split = jamotools.split_syllables(s)\n",
        "print(s_split)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "﻿태조 이성계 선대의 가계. 목조 이안사가 전주에서 삼척·의주를 거쳐 알동에 정착하다 \n",
            "태조 강헌 지인 계운 성문 신무 대왕(太祖康獻至仁啓運聖文神武大王)의 성은 이씨(李氏)요, 휘\n",
            "﻿ㅌㅐㅈㅗ ㅇㅣㅅㅓㅇㄱㅖ ㅅㅓㄴㄷㅐㅇㅢ ㄱㅏㄱㅖ. ㅁㅗㄱㅈㅗ ㅇㅣㅇㅏㄴㅅㅏㄱㅏ ㅈㅓㄴㅈㅜㅇㅔㅅㅓ ㅅㅏㅁㅊㅓㄱ·ㅇㅢㅈㅜㄹㅡㄹ ㄱㅓㅊㅕ ㅇㅏㄹㄷㅗㅇㅇㅔ ㅈㅓㅇㅊㅏㄱㅎㅏㄷㅏ \n",
            "ㅌㅐㅈㅗ ㄱㅏㅇㅎㅓㄴ ㅈㅣㅇㅣㄴ ㄱㅖㅇㅜㄴ ㅅㅓㅇㅁㅜㄴ ㅅㅣㄴㅁㅜ ㄷㅐㅇㅘㅇ(太祖康獻至仁啓運聖文神武大王)ㅇㅢ ㅅㅓㅇㅇㅡㄴ ㅇㅣㅆㅣ(李氏)ㅇㅛ, ㅎㅟ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ivfd0G5RRLJ",
        "outputId": "8e46fbe5-3fb9-49ff-9529-04f39f4a9b12",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 7.45 자모 결합 테스트\n",
        "s2 = jamotools.join_jamos(s_split)\n",
        "print(s2)\n",
        "print(s == s2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "﻿태조 이성계 선대의 가계. 목조 이안사가 전주에서 삼척·의주를 거쳐 알동에 정착하다 \n",
            "태조 강헌 지인 계운 성문 신무 대왕(太祖康獻至仁啓運聖文神武大王)의 성은 이씨(李氏)요, 휘\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtl5EkcrRRIV",
        "outputId": "8a2564d8-e258-4282-d51a-fa96cc3f9d2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 7.46 자모 토큰화\n",
        "# 텍스트를 자모 단위로 나눕니다. 데이터가 크기 때문에 약간 시간이 걸립니다.\n",
        "train_text_X = jamotools.split_syllables(train_text)\n",
        "vocab = sorted(set(train_text_X))\n",
        "vocab.append('UNK')\n",
        "print ('{} unique characters'.format(len(vocab)))\n",
        "\n",
        "# vocab list를 숫자로 맵핑하고, 반대도 실행합니다.\n",
        "char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "idx2char = np.array(vocab)\n",
        "\n",
        "text_as_int = np.array([char2idx[c] for c in train_text_X])\n",
        "\n",
        "# word2idx 의 일부를 알아보기 쉽게 print 해봅니다.\n",
        "print('{')\n",
        "for char,_ in zip(char2idx, range(10)):\n",
        "    print('  {:4s}: {:3d},'.format(repr(char), char2idx[char]))\n",
        "print('  ...\\n}')\n",
        "\n",
        "print('index of UNK: {}'.format(char2idx['UNK']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6198 unique characters\n",
            "{\n",
            "  '\\n':   0,\n",
            "  ' ' :   1,\n",
            "  '!' :   2,\n",
            "  '\"' :   3,\n",
            "  \"'\" :   4,\n",
            "  '(' :   5,\n",
            "  ')' :   6,\n",
            "  '+' :   7,\n",
            "  ',' :   8,\n",
            "  '-' :   9,\n",
            "  ...\n",
            "}\n",
            "index of UNK: 6197\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opyAlE-ZR4-o",
        "outputId": "a3b92078-bb3b-41b0-9c92-9901a08f4625",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 7.47 토큰 데이터 확인\n",
        "print(train_text_X[:20])\n",
        "print(text_as_int[:20])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "﻿ㅌㅐㅈㅗ ㅇㅣㅅㅓㅇㄱㅖ ㅅㅓㄴㄷㅐㅇ\n",
            "[6158   83   87   79   94    1   78  106   76   90   78   56   93    1\n",
            "   76   90   59   62   87   78]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MP0hfUCVRsp7",
        "outputId": "cb686b33-b05b-4c19-df1a-5f107b62a113",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 7.48 학습 데이터세트 생성\n",
        "seq_length = 80\n",
        "examples_per_epoch = len(text_as_int) // seq_length\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
        "\n",
        "char_dataset = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "for item in char_dataset.take(1):\n",
        "    print(idx2char[item.numpy()])\n",
        "    print(item.numpy())\n",
        "    \n",
        "def split_input_target(chunk):\n",
        "    return [chunk[:-1], chunk[-1]]\n",
        "\n",
        "train_dataset = char_dataset.map(split_input_target)\n",
        "for x,y in train_dataset.take(1):\n",
        "    print(idx2char[x.numpy()])\n",
        "    print(x.numpy())\n",
        "    print(idx2char[y.numpy()])\n",
        "    print(y.numpy())\n",
        "    \n",
        "BATCH_SIZE = 256\n",
        "steps_per_epoch = examples_per_epoch // BATCH_SIZE\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['\\ufeff' 'ㅌ' 'ㅐ' 'ㅈ' 'ㅗ' ' ' 'ㅇ' 'ㅣ' 'ㅅ' 'ㅓ' 'ㅇ' 'ㄱ' 'ㅖ' ' ' 'ㅅ' 'ㅓ' 'ㄴ'\n",
            " 'ㄷ' 'ㅐ' 'ㅇ' 'ㅢ' ' ' 'ㄱ' 'ㅏ' 'ㄱ' 'ㅖ' '.' ' ' 'ㅁ' 'ㅗ' 'ㄱ' 'ㅈ' 'ㅗ' ' ' 'ㅇ'\n",
            " 'ㅣ' 'ㅇ' 'ㅏ' 'ㄴ' 'ㅅ' 'ㅏ' 'ㄱ' 'ㅏ' ' ' 'ㅈ' 'ㅓ' 'ㄴ' 'ㅈ' 'ㅜ' 'ㅇ' 'ㅔ' 'ㅅ' 'ㅓ'\n",
            " ' ' 'ㅅ' 'ㅏ' 'ㅁ' 'ㅊ' 'ㅓ' 'ㄱ' '·' 'ㅇ' 'ㅢ' 'ㅈ' 'ㅜ' 'ㄹ' 'ㅡ' 'ㄹ' ' ' 'ㄱ' 'ㅓ'\n",
            " 'ㅊ' 'ㅕ' ' ' 'ㅇ' 'ㅏ' 'ㄹ' 'ㄷ' 'ㅗ' 'ㅇ' 'ㅇ']\n",
            "[6158   83   87   79   94    1   78  106   76   90   78   56   93    1\n",
            "   76   90   59   62   87   78  105    1   56   86   56   93   10    1\n",
            "   72   94   56   79   94    1   78  106   78   86   59   76   86   56\n",
            "   86    1   79   90   59   79   99   78   91   76   90    1   76   86\n",
            "   72   81   90   56   36   78  105   79   99   64  104   64    1   56\n",
            "   90   81   92    1   78   86   64   62   94   78   78]\n",
            "['\\ufeff' 'ㅌ' 'ㅐ' 'ㅈ' 'ㅗ' ' ' 'ㅇ' 'ㅣ' 'ㅅ' 'ㅓ' 'ㅇ' 'ㄱ' 'ㅖ' ' ' 'ㅅ' 'ㅓ' 'ㄴ'\n",
            " 'ㄷ' 'ㅐ' 'ㅇ' 'ㅢ' ' ' 'ㄱ' 'ㅏ' 'ㄱ' 'ㅖ' '.' ' ' 'ㅁ' 'ㅗ' 'ㄱ' 'ㅈ' 'ㅗ' ' ' 'ㅇ'\n",
            " 'ㅣ' 'ㅇ' 'ㅏ' 'ㄴ' 'ㅅ' 'ㅏ' 'ㄱ' 'ㅏ' ' ' 'ㅈ' 'ㅓ' 'ㄴ' 'ㅈ' 'ㅜ' 'ㅇ' 'ㅔ' 'ㅅ' 'ㅓ'\n",
            " ' ' 'ㅅ' 'ㅏ' 'ㅁ' 'ㅊ' 'ㅓ' 'ㄱ' '·' 'ㅇ' 'ㅢ' 'ㅈ' 'ㅜ' 'ㄹ' 'ㅡ' 'ㄹ' ' ' 'ㄱ' 'ㅓ'\n",
            " 'ㅊ' 'ㅕ' ' ' 'ㅇ' 'ㅏ' 'ㄹ' 'ㄷ' 'ㅗ' 'ㅇ']\n",
            "[6158   83   87   79   94    1   78  106   76   90   78   56   93    1\n",
            "   76   90   59   62   87   78  105    1   56   86   56   93   10    1\n",
            "   72   94   56   79   94    1   78  106   78   86   59   76   86   56\n",
            "   86    1   79   90   59   79   99   78   91   76   90    1   76   86\n",
            "   72   81   90   56   36   78  105   79   99   64  104   64    1   56\n",
            "   90   81   92    1   78   86   64   62   94   78]\n",
            "ㅇ\n",
            "78\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TazYgfrsRsly",
        "outputId": "b60a06a6-a9cc-4a23-f850-017f82e67122",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 7.49 자소 단위 생성 모델 정의\n",
        "total_chars = len(vocab)\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(total_chars, 100, input_length=seq_length),\n",
        "    tf.keras.layers.LSTM(units=400),\n",
        "    tf.keras.layers.Dense(total_chars, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 80, 100)           619800    \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 400)               801600    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 6198)              2485398   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,906,798\n",
            "Trainable params: 3,906,798\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xjv4zsxFRRF9",
        "outputId": "a53a42e9-ec8f-4a69-aabc-5366fb645042",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        }
      },
      "source": [
        "# 7.50 자소 단위 생성 모델 학습\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "def testmodel(epoch, logs):\n",
        "    if epoch % 5 != 0 and epoch != 99:\n",
        "        return\n",
        "    \n",
        "    test_sentence = train_text[:48]\n",
        "    test_sentence = jamotools.split_syllables(test_sentence)\n",
        "\n",
        "    next_chars = 300\n",
        "    for _ in range(next_chars):\n",
        "        test_text_X = test_sentence[-seq_length:]\n",
        "        test_text_X = np.array([char2idx[c] if c in char2idx else char2idx['UNK'] for c in test_text_X])\n",
        "        test_text_X = pad_sequences([test_text_X], maxlen=seq_length, padding='pre', value=char2idx['UNK'])\n",
        "\n",
        "        output_idx = model.predict_classes(test_text_X)\n",
        "        test_sentence += idx2char[output_idx[0]]\n",
        "    \n",
        "    print()\n",
        "    print(jamotools.join_jamos(test_sentence))\n",
        "    print()\n",
        "\n",
        "testmodelcb = tf.keras.callbacks.LambdaCallback(on_epoch_end=testmodel)\n",
        "\n",
        "history = model.fit(train_dataset.repeat(), epochs=100, steps_per_epoch=steps_per_epoch, callbacks=[testmodelcb], verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-c842ef4688f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mtestmodelcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLambdaCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtestmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtestmodelcb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2PIJeXRvEw-",
        "outputId": "9d2d26bd-2645-4330-eb4c-ef9276844bd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "source": [
        "# 7.51 임의의 문장을 사용한 생성 결과 확인\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "test_sentence = '동헌에 나가 공무를 본 후 활 십오 순을 쏘았다'\n",
        "test_sentence = jamotools.split_syllables(test_sentence)\n",
        "\n",
        "next_chars = 300\n",
        "for _ in range(next_chars):\n",
        "    test_text_X = test_sentence[-seq_length:]\n",
        "    test_text_X = np.array([char2idx[c] if c in char2idx else char2idx['UNK'] for c in test_text_X])\n",
        "    test_text_X = pad_sequences([test_text_X], maxlen=seq_length, padding='pre', value=char2idx['UNK'])\n",
        "    \n",
        "    output_idx = model.predict_classes(test_text_X)\n",
        "    test_sentence += idx2char[output_idx[0]]\n",
        "    \n",
        "\n",
        "print(jamotools.join_jamos(test_sentence))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "동헌에 나가 공무를 본 후 활 십오 순을 쏘았다. 임금이 말하기를,\n",
            "\"이보다 큰 공상은 그 집에 돌아오다\n",
            "정사를 보았다. 임금이 말하기를,\n",
            "\"이방성을 아뢰다\n",
            "함길도 감사가 이미 나라를 행하였다.상왕이 그 사람을 금하다\n",
            "임금이 말하기를,\n",
            "\"이보다 큰 공상은 그 집에 돌아온다. 【모든 것을 보내어 여러 관원은 농산ㄱ\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}